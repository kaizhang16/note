<!DOCTYPE html>
<html lang="cn" dir=>

<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="术语  表 1: 术语  缩写 全称 含义    C Context 场景  CTR Click Through Rate 点击率  CVR Conversion Rate 转化率  DMP Data Management Platform 数据管理平台  FFM Field-aware Factorization Machine 域感知因子分解机  FM Factorization Machine 因子分解机  I Item 物品  MLP Multilayer Perception 多层感知机  U User 用户     架构  图 1: 推荐系统架构  算法 不同算法的优缺点  表 2: 不同算法的优缺点  算法 优点 缺点    UserCF 符合直觉（兴趣相似的朋友喜欢的物品，我也喜欢） 用户数远大于物品数   社交特性更强，适于发现热点 用户历史数据向量很稀疏  ItemCF 适于兴趣变化较为稳定的应用 泛化能力弱，头部效应强   直观，可解释性强 无法有效引入场景信息  矩阵分解 泛化能力强 不方便融合特征   空间复杂度低 不好冷启动   便于与神经网络集成   逻辑回归 融合多种特征 无法特征交叉、筛选   假设 \(y\) 服从伯努利分布，有物理意义    是各特征的加权和，可解释性强    易于并行化、模型简单、易于训练   POLY2 特征交叉 特征向量更稀疏，不好训练    参数增多  FM 参数从 POLY2 的 \(n^2\) 下降到 \(nk\)    比 POLY2 更适于稀疏数据，泛化能力强    易于上线   FFM 比 FM 表达能力强 计算复杂度上升到 \(kn^2\)  GBDT&#43;LR 特征工程模型化   LS-PLM 能挖掘非线性模式    引入 L1 惩罚，模型稀疏   AutoRec 第一次使用深度学习框架   Deep Crossing 特征间深度交叉   NeuralCF 用户向量和物品向量更充分地交叉 没有引入更多特征   表达能力比矩阵分解强    可以灵活选择互操作层   PNN 强调不同特征之间的交互 简化操作丢失信息  Wide &amp; Deep 综合记忆能力和泛化能力    开拓了融合不同网络结构的新思路   Deep &amp; Cross Wide 部分的特征自动交叉   DIEN 预测下一次购买，更符合业务目标 训练复杂度高    串行推断  DRN 变静态为动态，在线训练      协同过滤 共现矩阵 用户为行坐标（记用户总数为 \(m\)）、物品为列坐标（即物品总数为 \(n\)）的 \(m\times n\) 维矩阵。">
<meta name="theme-color" content="#FFFFFF"><meta property="og:title" content="推荐系统" />
<meta property="og:description" content="术语  表 1: 术语  缩写 全称 含义    C Context 场景  CTR Click Through Rate 点击率  CVR Conversion Rate 转化率  DMP Data Management Platform 数据管理平台  FFM Field-aware Factorization Machine 域感知因子分解机  FM Factorization Machine 因子分解机  I Item 物品  MLP Multilayer Perception 多层感知机  U User 用户     架构  图 1: 推荐系统架构  算法 不同算法的优缺点  表 2: 不同算法的优缺点  算法 优点 缺点    UserCF 符合直觉（兴趣相似的朋友喜欢的物品，我也喜欢） 用户数远大于物品数   社交特性更强，适于发现热点 用户历史数据向量很稀疏  ItemCF 适于兴趣变化较为稳定的应用 泛化能力弱，头部效应强   直观，可解释性强 无法有效引入场景信息  矩阵分解 泛化能力强 不方便融合特征   空间复杂度低 不好冷启动   便于与神经网络集成   逻辑回归 融合多种特征 无法特征交叉、筛选   假设 \(y\) 服从伯努利分布，有物理意义    是各特征的加权和，可解释性强    易于并行化、模型简单、易于训练   POLY2 特征交叉 特征向量更稀疏，不好训练    参数增多  FM 参数从 POLY2 的 \(n^2\) 下降到 \(nk\)    比 POLY2 更适于稀疏数据，泛化能力强    易于上线   FFM 比 FM 表达能力强 计算复杂度上升到 \(kn^2\)  GBDT&#43;LR 特征工程模型化   LS-PLM 能挖掘非线性模式    引入 L1 惩罚，模型稀疏   AutoRec 第一次使用深度学习框架   Deep Crossing 特征间深度交叉   NeuralCF 用户向量和物品向量更充分地交叉 没有引入更多特征   表达能力比矩阵分解强    可以灵活选择互操作层   PNN 强调不同特征之间的交互 简化操作丢失信息  Wide &amp; Deep 综合记忆能力和泛化能力    开拓了融合不同网络结构的新思路   Deep &amp; Cross Wide 部分的特征自动交叉   DIEN 预测下一次购买，更符合业务目标 训练复杂度高    串行推断  DRN 变静态为动态，在线训练      协同过滤 共现矩阵 用户为行坐标（记用户总数为 \(m\)）、物品为列坐标（即物品总数为 \(n\)）的 \(m\times n\) 维矩阵。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://kaizhang91.github.io/note/AI/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/" />

<title>推荐系统 | 凯的笔记</title>
<link rel="manifest" href="/note/manifest.json">
<link rel="icon" href="/note/favicon.png" type="image/x-icon">
<link rel="stylesheet" href="/note/book.min.3a7020b7bdb6727663c3b39ea050038a416a055141fadfe7e448887f123d96be.css" integrity="sha256-OnAgt722cnZjw7OeoFADikFqBVFB&#43;t/n5EiIfxI9lr4=">
<script defer src="/note/cn.search.min.1277336dd15e318abda643ee499ea68781fe026c4871fb46f0890e5beaaafdff.js" integrity="sha256-EnczbdFeMYq9pkPuSZ6mh4H&#43;AmxIcftG8IkOW&#43;qq/f8="></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->

  
<link rel="icon" href="/note/favicon.ico" type="image/x-icon">


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.4.1/styles/dark.min.css">




</head>

<body dir=>
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      
  <nav>
<h2 class="book-brand">
  <a href="/note"><span>凯的笔记</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="搜索" aria-label="搜索" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>











  

  



  
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-cfbd43d7dbc20d8fbe7979a2801e3144" class="toggle" checked />
    <label for="section-cfbd43d7dbc20d8fbe7979a2801e3144" class="flex justify-between">
      <a  class="">AI</a>
      <span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/AI/dev_env/" class="">开发环境</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/AI/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/" class=" active">推荐系统</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="">机器学习</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/AI/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="">深度学习</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/AI/%E9%A1%B9%E7%9B%AE/" class="">项目</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-4af17239608ef6224ba6d5135a065aee" class="toggle"  />
    <label for="section-4af17239608ef6224ba6d5135a065aee" class="flex justify-between">
      <a  class="">CS</a>
      <span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/CS/http/" class="">HTTP</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/CS/linux/" class="">Linux</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/CS/oauth2/" class="">OAuth 2</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/CS/transmission/" class="">传输</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/CS/compress/" class="">压缩</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/CS/security/" class="">安全</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/CS/ci/" class="">持续集成</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/CS/database/" class="">数据库</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/CS/data-type/" class="">数据类型</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/CS/%E7%AE%97%E6%B3%95/" class="">算法</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/CS/encoding/" class="">编码</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/CS/network/" class="">网络</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-817f67a0d4c538392ea74ac855517ffe" class="toggle"  />
    <label for="section-817f67a0d4c538392ea74ac855517ffe" class="flex justify-between">
      <a  class="">LeetCode</a>
      <span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/LeetCode/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" class="">动态规划</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/LeetCode/%E6%95%B0%E5%AD%97/" class="">数字</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/LeetCode/%E6%95%B0%E7%BB%84/" class="">数组</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-9bfe21a0187b525fe1f8c33e218fae99" class="toggle"  />
    <label for="section-9bfe21a0187b525fe1f8c33e218fae99" class="flex justify-between">
      <a  class="">NLP</a>
      <span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/NLP/GPT-2/" class="">GPT-2</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/NLP/LSTM_GRU/" class="">LSTM 与 GRU</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/NLP/Transformer/" class="">Transformer</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-70bdf8d87af46a79686d31378c1d7d85" class="toggle"  />
    <label for="section-70bdf8d87af46a79686d31378c1d7d85" class="flex justify-between">
      <a  class="">工具</a>
      <span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E5%B7%A5%E5%85%B7/git/" class="">Git</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E5%B7%A5%E5%85%B7/ipad/" class="">iPad</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E5%B7%A5%E5%85%B7/Linux/" class="">Linux</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E5%B7%A5%E5%85%B7/Windows/" class="">Windows</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E5%B7%A5%E5%85%B7/Word/" class="">Word</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E5%B7%A5%E5%85%B7/writing/" class="">写作</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E5%B7%A5%E5%85%B7/search/" class="">搜索</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E5%B7%A5%E5%85%B7/%E6%96%87%E7%8C%AE%E7%AE%A1%E7%90%86/" class="">文献管理</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E5%B7%A5%E5%85%B7/format/" class="">格式</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E5%B7%A5%E5%85%B7/browser/" class="">浏览器</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E5%B7%A5%E5%85%B7/%E7%BC%96%E8%BE%91%E5%99%A8/" class="">编辑器</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E5%B7%A5%E5%85%B7/project-management/" class="">项目管理</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1f9a426141100f8f7ab323c20cac8352" class="toggle"  />
    <label for="section-1f9a426141100f8f7ab323c20cac8352" class="flex justify-between">
      <a  class="">数学</a>
      <span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E6%95%B0%E5%AD%A6/linear_algebra/" class="">线性代数</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E6%95%B0%E5%AD%A6/statistics/" class="">统计</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-49cd3dd12728d4fd4ae01f7800801d13" class="toggle"  />
    <label for="section-49cd3dd12728d4fd4ae01f7800801d13" class="flex justify-between">
      <a  class="">编程</a>
      <span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E7%BC%96%E7%A8%8B/bash/" class="">Bash</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E7%BC%96%E7%A8%8B/c&#43;&#43;/" class="">C&#43;&#43;</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E7%BC%96%E7%A8%8B/css/" class="">CSS</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E7%BC%96%E7%A8%8B/dhall/" class="">Dhall</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E7%BC%96%E7%A8%8B/fish-shell/" class="">fish-shell</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E7%BC%96%E7%A8%8B/flutter/" class="">Flutter</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E7%BC%96%E7%A8%8B/golang/" class="">Golang</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E7%BC%96%E7%A8%8B/html/" class="">HTML</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E7%BC%96%E7%A8%8B/js/" class="">JavaScript</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E7%BC%96%E7%A8%8B/pandoc/" class="">Pandoc</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E7%BC%96%E7%A8%8B/PowerShell/" class="">PowerShell</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E7%BC%96%E7%A8%8B/python/" class="">Python</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E7%BC%96%E7%A8%8B/rust/" class="">Rust</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E7%BC%96%E7%A8%8B/TeX/" class="">TeX</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E7%BC%96%E7%A8%8B/toml/" class="">Toml</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E7%BC%96%E7%A8%8B/zsh/" class="">Zsh</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E7%BC%96%E7%A8%8B/template/" class="">模板</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1e20c44ce142ce73dcb99537728dc9a3" class="toggle"  />
    <label for="section-1e20c44ce142ce73dcb99537728dc9a3" class="flex justify-between">
      <a  class="">视觉</a>
      <span>▾</span>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E8%A7%86%E8%A7%89/unity/" class="">Unity</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E8%A7%86%E8%A7%89/image/" class="">图像</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang91.github.io/note/%E8%A7%86%E8%A7%89/video/" class="">视频</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>















</nav>




  <script>!function(){var a=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(b){localStorage.setItem("menu.scrollTop",a.scrollTop)}),a.scrollTop=localStorage.getItem("menu.scrollTop")}()</script>


 
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/note/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>推荐系统</strong>

  <label for="toc-control">
    
    <img src="/note/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  


  </aside>
  
 
      </header>

      
      
  <article class="markdown"><h1 id="术语">术语</h1>
<div id="tbl:terminology">
<table>
<caption>表 1: 术语</caption>
<thead>
<tr class="header">
<th>缩写</th>
<th>全称</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>C</td>
<td>Context</td>
<td>场景</td>
</tr>
<tr class="even">
<td>CTR</td>
<td>Click Through Rate</td>
<td>点击率</td>
</tr>
<tr class="odd">
<td>CVR</td>
<td>Conversion Rate</td>
<td>转化率</td>
</tr>
<tr class="even">
<td>DMP</td>
<td>Data Management Platform</td>
<td>数据管理平台</td>
</tr>
<tr class="odd">
<td>FFM</td>
<td>Field-aware Factorization Machine</td>
<td>域感知因子分解机</td>
</tr>
<tr class="even">
<td>FM</td>
<td>Factorization Machine</td>
<td>因子分解机</td>
</tr>
<tr class="odd">
<td>I</td>
<td>Item</td>
<td>物品</td>
</tr>
<tr class="even">
<td>MLP</td>
<td>Multilayer Perception</td>
<td>多层感知机</td>
</tr>
<tr class="odd">
<td>U</td>
<td>User</td>
<td>用户</td>
</tr>
</tbody>
</table>
</div>
<h1 id="架构">架构</h1>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/architecture.webp" id="fig:architecture" alt="图 1: 推荐系统架构" /><figcaption aria-hidden="true">图 1: 推荐系统架构</figcaption>
</figure>
<h1 id="算法">算法</h1>
<h2 id="不同算法的优缺点">不同算法的优缺点</h2>
<div id="tbl:algorithm_pros_cons">
<table>
<caption>表 2: 不同算法的优缺点</caption>
<thead>
<tr class="header">
<th>算法</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>UserCF</td>
<td>符合直觉（兴趣相似的朋友喜欢的物品，我也喜欢）</td>
<td>用户数远大于物品数</td>
</tr>
<tr class="even">
<td></td>
<td>社交特性更强，适于发现热点</td>
<td>用户历史数据向量很稀疏</td>
</tr>
<tr class="odd">
<td>ItemCF</td>
<td>适于兴趣变化较为稳定的应用</td>
<td>泛化能力弱，头部效应强</td>
</tr>
<tr class="even">
<td></td>
<td>直观，可解释性强</td>
<td>无法有效引入场景信息</td>
</tr>
<tr class="odd">
<td>矩阵分解</td>
<td>泛化能力强</td>
<td>不方便融合特征</td>
</tr>
<tr class="even">
<td></td>
<td>空间复杂度低</td>
<td>不好冷启动</td>
</tr>
<tr class="odd">
<td></td>
<td>便于与神经网络集成</td>
<td></td>
</tr>
<tr class="even">
<td>逻辑回归</td>
<td>融合多种特征</td>
<td>无法特征交叉、筛选</td>
</tr>
<tr class="odd">
<td></td>
<td>假设 <span class="math inline">\(y\)</span> 服从伯努利分布，有物理意义</td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>是各特征的加权和，可解释性强</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>易于并行化、模型简单、易于训练</td>
<td></td>
</tr>
<tr class="even">
<td>POLY2</td>
<td>特征交叉</td>
<td>特征向量更稀疏，不好训练</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td>参数增多</td>
</tr>
<tr class="even">
<td>FM</td>
<td>参数从 POLY2 的 <span class="math inline">\(n^2\)</span> 下降到 <span class="math inline">\(nk\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>比 POLY2 更适于稀疏数据，泛化能力强</td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>易于上线</td>
<td></td>
</tr>
<tr class="odd">
<td>FFM</td>
<td>比 FM 表达能力强</td>
<td>计算复杂度上升到 <span class="math inline">\(kn^2\)</span></td>
</tr>
<tr class="even">
<td>GBDT+LR</td>
<td>特征工程模型化</td>
<td></td>
</tr>
<tr class="odd">
<td>LS-PLM</td>
<td>能挖掘非线性模式</td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>引入 L1 惩罚，模型稀疏</td>
<td></td>
</tr>
<tr class="odd">
<td>AutoRec</td>
<td>第一次使用深度学习框架</td>
<td></td>
</tr>
<tr class="even">
<td>Deep Crossing</td>
<td>特征间深度交叉</td>
<td></td>
</tr>
<tr class="odd">
<td>NeuralCF</td>
<td>用户向量和物品向量更充分地交叉</td>
<td>没有引入更多特征</td>
</tr>
<tr class="even">
<td></td>
<td>表达能力比矩阵分解强</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>可以灵活选择互操作层</td>
<td></td>
</tr>
<tr class="even">
<td>PNN</td>
<td>强调不同特征之间的交互</td>
<td>简化操作丢失信息</td>
</tr>
<tr class="odd">
<td>Wide &amp; Deep</td>
<td>综合记忆能力和泛化能力</td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>开拓了融合不同网络结构的新思路</td>
<td></td>
</tr>
<tr class="odd">
<td>Deep &amp; Cross</td>
<td>Wide 部分的特征自动交叉</td>
<td></td>
</tr>
<tr class="even">
<td>DIEN</td>
<td>预测下一次购买，更符合业务目标</td>
<td>训练复杂度高</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td>串行推断</td>
</tr>
<tr class="even">
<td>DRN</td>
<td>变静态为动态，在线训练</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<h2 id="协同过滤">协同过滤</h2>
<h3 id="共现矩阵">共现矩阵</h3>
<p>用户为行坐标（记用户总数为 <span class="math inline">\(m\)</span>）、物品为列坐标（即物品总数为 <span class="math inline">\(n\)</span>）的 <span class="math inline">\(m\times n\)</span> 维矩阵。</p>
<h3 id="相似度">相似度</h3>
<h4 id="余弦相似度">余弦相似度</h4>
<p><span id="eq:cosine_similarity"><span class="math display">\[\sim(\v{i},\v{j}) = \cos(\v{i}, \v{j}) = \frac{\v{i}\cdot\v{j}}{\lVert\v{i}\rVert\cdot\lVert\v{j}\rVert}\qquad(1)\]</span></span></p>
<p>其中，<span class="math inline">\(\v{i}\)</span>、<span class="math inline">\(\v{j}\)</span> 均表示用户向量。</p>
<h4 id="皮尔逊相关系数">皮尔逊相关系数</h4>
<p><span id="eq:pearsion_coefficient"><span class="math display">\[\sim(i,j) = \frac{\sum_{p\in P}(R_{i,p} - \mean{R_i})(R_{j,p}-\mean{R_j})}{\sqrt{\sum_{p\in P}(R_{i,p}-\mean{R_i})^2}\sqrt{\sum_{p\in P}(R_{j,p}-\mean{R_j})^2}}\qquad(2)\]</span></span></p>
<p>其中，<span class="math inline">\(R_{i,p}\)</span> 表示用户 <span class="math inline">\(i\)</span> 对物品 <span class="math inline">\(p\)</span> 的评分；<span class="math inline">\(\mean{R_i}\)</span> 表示用户 <span class="math inline">\(i\)</span> 对所有物品的平均评分；<span class="math inline">\(P\)</span> 代表所有物品的集合。</p>
<blockquote>
<p>皮尔逊相关系数减小了用户评分偏置的影响。</p>
</blockquote>
<h4 id="皮尔逊相关系数拓展">皮尔逊相关系数拓展</h4>
<p><span id="eq:pearsion_coefficient_item"><span class="math display">\[\sim(i,j) = \frac{\sum_{p\in P}(R_{i,p} - \mean{R_p})(R_{j,p}-\mean{R_p})}{\sqrt{\sum_{p\in P}(R_{i,p}-\mean{R_p})^2}\sqrt{\sum_{p\in P}(R_{j,p}-\mean{R_p})^2}}\qquad(3)\]</span></span></p>
<p>其中，<span class="math inline">\(R_{i,p}\)</span> 表示用户 <span class="math inline">\(i\)</span> 对物品 <span class="math inline">\(p\)</span> 的评分；<span class="math inline">\(\mean{R_p}\)</span> 表示物品 <span class="math inline">\(p\)</span> 的平均评分；<span class="math inline">\(P\)</span> 代表所有物品的集合。</p>
<blockquote>
<p>式. 3 减小了物品评分偏置的影响。</p>
</blockquote>
<h3 id="usercf">UserCF</h3>
<p>基于用户的协同过滤。</p>
<p><span id="eq:user_cf"><span class="math display">\[R_{u,p} = \frac{\sum_{s\in S}w_{u,s}R_{s,p}}{\sum_{s\in S}w_{u,s}}\qquad(4)\]</span></span></p>
<p>其中，<span class="math inline">\(R_{s,p}\)</span> 表示用户 <span class="math inline">\(s\)</span> 对物品 <span class="math inline">\(p\)</span> 的评分；<span class="math inline">\(w_{u,s}\)</span> 表示用户 <span class="math inline">\(u\)</span> 与用户 <span class="math inline">\(s\)</span> 的相似度。</p>
<ul>
<li>根据用户向量找到 top n 相似用户</li>
<li>将相似用户对物品的评分加权平均，即可得到目标用户对物品的评分</li>
</ul>
<h3 id="itemcf">ItemCF</h3>
<p>基于物品相似度的协同过滤。</p>
<p><span id="eq:item_cf"><span class="math display">\[R_{u,p} = \sum_{h\in H}w_{p,h}R_{u,h}\qquad(5)\]</span></span></p>
<p>其中，<span class="math inline">\(R_{u,h}\)</span> 表示用户 <span class="math inline">\(u\)</span> 对物品 <span class="math inline">\(h\)</span> 的评分；<span class="math inline">\(w_{p,h}\)</span> 表示物品 <span class="math inline">\(p\)</span> 与物品 <span class="math inline">\(h\)</span> 的相似度；<span class="math inline">\(H\)</span> 表示用户 <span class="math inline">\(u\)</span> 的正反馈物品集合。</p>
<ul>
<li>根据物品向量找到 top k 相似物品</li>
<li>将用户对相似物品的评分加权平均，即得用户对目标物品的评分</li>
</ul>
<h2 id="矩阵分解">矩阵分解</h2>
<p>分解共现矩阵得到用户和物品的隐向量：</p>
<p><span id="eq:matrix_factorization"><span class="math display">\[\m{R} = \m{U}\m{V}\qquad(6)\]</span></span></p>
<p>其中，<span class="math inline">\(\m{R}\)</span> 为 <span class="math inline">\(m\times n\)</span> 维的共现矩阵，<span class="math inline">\(\m{U}\)</span> 为 <span class="math inline">\(m\times k\)</span> 维的用户矩阵， <span class="math inline">\(\m{V}\)</span> 为 <span class="math inline">\(k\times n\)</span> 维的物品矩阵。</p>
<p><span id="eq:matrix_factorization_r"><span class="math display">\[\hat{r}_{ui} = \T{\v{q}}_i\v{p}_u\qquad(7)\]</span></span></p>
<p>其中，<span class="math inline">\(\v{p}_u\)</span> 表示 <span class="math inline">\(\m{U}\)</span> 的第 <span class="math inline">\(u\)</span> 行组成的向量，<span class="math inline">\(\v{q}_i\)</span> 表示 <span class="math inline">\(\m{V}\)</span> 中的第 <span class="math inline">\(i\)</span> 列组成的向量。</p>
<h3 id="奇异值分解">奇异值分解</h3>
<ul>
<li>共现矩阵有大量缺失值，不适于直接 SVD</li>
<li>计算复杂度高</li>
</ul>
<h3 id="梯度下降">梯度下降</h3>
<p>损失函数：</p>
<p><span id="eq:matrix_factorization_loss"><span class="math display">\[\min\sum_{(u,i)\in K}(r_{ui} - \T{\v{q}}_i\v{p}_u)^2\qquad(8)\]</span></span></p>
<p>其中，<span class="math inline">\(K\)</span> 是所有用户评分样本的集合。</p>
<h3 id="消除用户和物品打分的偏差">消除用户和物品打分的偏差</h3>
<p><span id="eq:matrix_factorization_r_bias"><span class="math display">\[\hat{r}_{ui} = \mu + b_i + b_u + \T{\v{q}}_i\v{p}_u\qquad(9)\]</span></span></p>
<p>其中，<span class="math inline">\(\mu\)</span> 是全局偏差，<span class="math inline">\(b_i\)</span> 是物品偏差，<span class="math inline">\(b_u\)</span> 是用户偏差。</p>
<h2 id="逻辑回归">逻辑回归</h2>
<h3 id="输出">输出</h3>
<p><span id="eq:lr_output"><span class="math display">\[\hat{y} = \sigmoid(\T{\v{x}}\v{w} + b)\qquad(10)\]</span></span></p>
<h3 id="损失函数">损失函数</h3>
<p><span id="eq:lr_loss"><span class="math display">\[
\begin{align}
J(\v{w}) &amp;= \frac{1}{m}\sum_{i=1}^m H(p(\v{y}), p(\hat{\v{y}})) \\
&amp;= -\frac{1}{m}\sum_{i=1}^m[y_i\log f_{\v{w}}(\v{x}_i) + (1-y_i)\log (1-f_{\v{w}}(\v{x}_i))]
\end{align}
\qquad(11)\]</span></span></p>
<blockquote>
<p>也可以用极大似然估计解释，<span class="math inline">\(P(y\mid \v{x};\v{w}) = (f_{\v{w}}(\v{x}))^y(1-f_{\v{w}}(\v{x}))^{1-y}\)</span>。</p>
</blockquote>
<h2 id="fm---ffm">FM -&gt; FFM</h2>
<h3 id="poly2">POLY2</h3>
<p><span id="eq:poly2"><span class="math display">\[\phi\mathrm{POLY2}(\v{w},\v{x}) =
\sum_{j_1=1}^{n-1}\sum_{j_2=j_1+1}^n w_{h(j_1,j_2)}x_{j_1}x_{j_2}\qquad(12)\]</span></span></p>
<h3 id="fm">FM</h3>
<p><span id="eq:fm"><span class="math display">\[\phi\mathrm{FM}(\v{w},\v{x}) =
\sum_{j_1=1}^{n-1}\sum_{j_2=j_1+1}^n (\v{w}_{j_1}\cdot\v{w}_{j_2})x_{j_1}x_{j_2}\qquad(13)\]</span></span></p>
<h3 id="ffm">FFM</h3>
<p><span id="eq:ffm"><span class="math display">\[\phi\mathrm{FFM}(\v{w},\v{x}) =
\sum_{j_1=1}^{n-1}\sum_{j_2=j_1+1}^n (\v{w}_{j_1,f_2}\cdot\v{w}_{j_2,f_1})x_{j_1}x_{j_2}\qquad(14)\]</span></span></p>
<h2 id="gbdt-lr">GBDT + LR</h2>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/GBDT&#43;LR_architecture.jpg" id="fig:GBDT_LR_architecture" alt="图 2: GBDT+LR 架构" /><figcaption aria-hidden="true">图 2: GBDT+LR 架构</figcaption>
</figure>
<h2 id="ls-plm">LS-PLM</h2>
<h3 id="输出-1">输出</h3>
<p><span id="eq:ls_plm_y"><span class="math display">\[
\begin{align}
f(\v{x}) &amp;= \sum_{i=1}^m \pi_i(\v{x})\cdot\eta_i(\v{x}) \\
&amp;= \sum_{i=1}^m \frac{\e^{\v{\mu_i}\cdot\v{x}}}{\sum_{j=1}^m\e^{\v{\mu_j}\cdot\v{x}}}\cdot\frac{1}{1+\e^{-\v{w_i}\cdot\v{x}}}
\end{align}
\qquad(15)\]</span></span></p>
<p>其中，<span class="math inline">\(m\)</span> 为分片数，<span class="math inline">\(\pi\)</span> 为聚类函数（这里采用 softmax 对样本进行多分类）。</p>
<h2 id="autorec">AutoRec</h2>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/auto_rec_architecture.png" id="fig:auto_rec_architecture" alt="图 3: AutoRec 架构[1]" /><figcaption aria-hidden="true">图 3: AutoRec 架构<span class="citation" data-cites="sedhain2015autorec"><sup>[<a href="#ref-sedhain2015autorec" role="doc-biblioref">1</a>]</sup></span></figcaption>
</figure>
<h3 id="损失函数-1">损失函数</h3>
<p><span id="eq:auto_rec_loss"><span class="math display">\[\min_{\theta}\left[\sum_{\v{r}\in S}\lVert\v{r}-h(\v{r};\theta)\rVert_2^2
+ \frac{\lambda}{2}(\lVert\m{W}_F^2\rVert + \lVert\m{V}\rVert_F^2)\right]\qquad(16)\]</span></span></p>
<p>其中，<span class="math inline">\(h(\v{r};\theta)\)</span> 为重建函数；<span class="math inline">\(\v{r}^{(i)}=\T{(R_{1i},\dots,R_{mi})}\)</span> 为物品 <span class="math inline">\(i\)</span> 的评分向量。</p>
<h3 id="重建函数">重建函数</h3>
<p><span id="eq:auto_rec_reconstruction"><span class="math display">\[h(\v{r};\theta)=f(\m{W}\cdot g(\m{V}\v{r}+\mu)+b)\qquad(17)\]</span></span></p>
<h3 id="输出-2">输出</h3>
<p><span id="eq:auto_rec_output"><span class="math display">\[\hat{R}_{ui} = h(\v{r}^{(i)};\theta)_u\qquad(18)\]</span></span></p>
<h2 id="deep-crossing">Deep Crossing</h2>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/deep_crossing_architecture.png" id="fig:deep_crossing_architecture" alt="图 4: Deep Crossing 架构[2]" /><figcaption aria-hidden="true">图 4: Deep Crossing 架构<span class="citation" data-cites="shan2016deep"><sup>[<a href="#ref-shan2016deep" role="doc-biblioref">2</a>]</sup></span></figcaption>
</figure>
<h3 id="残差神经网络">残差神经网络</h3>
<p>好处：</p>
<ul>
<li>减少过拟合</li>
<li>减弱梯度消失现象，加快收敛速度</li>
</ul>
<h2 id="neuralcf">NeuralCF</h2>
<p>用多层神经网络代替矩阵分解的内积操作。</p>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/neural_cf_architecture.png" id="fig:neural_cf_architecture" alt="图 5: NeuralCF 架构[3]" /><figcaption aria-hidden="true">图 5: NeuralCF 架构<span class="citation" data-cites="he2017neural"><sup>[<a href="#ref-he2017neural" role="doc-biblioref">3</a>]</sup></span></figcaption>
</figure>
<h2 id="pnn">PNN</h2>
<p>乘积层代替 Deep Crossing 模型中的 Stacking 层。</p>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/pnn_architecture.png" id="fig:pnn_architecture" alt="图 6: PNN 架构[4]" /><figcaption aria-hidden="true">图 6: PNN 架构<span class="citation" data-cites="qu2016product"><sup>[<a href="#ref-qu2016product" role="doc-biblioref">4</a>]</sup></span></figcaption>
</figure>
<h2 id="wide-deep">Wide &amp; Deep</h2>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/wide_deep_architecture.png" id="fig:wide_deep_architecture" alt="图 7: Wide &amp; Deep 架构[5]" /><figcaption aria-hidden="true">图 7: Wide &amp; Deep 架构<span class="citation" data-cites="cheng2016wide"><sup>[<a href="#ref-cheng2016wide" role="doc-biblioref">5</a>]</sup></span></figcaption>
</figure>
<p>Cross Product Transformation 为：</p>
<p><span class="math display">\[\phi_k(\v{x}) = \prod_{i=1}^d x_i^{c_{ki}}\quad c_{ki}\in\{0,1\}\]</span></p>
<p>其中，<span class="math inline">\(c_{ki}\)</span> 当第 <span class="math inline">\(i\)</span> 个特征属于第 <span class="math inline">\(k\)</span> 个组合特征时为 <span class="math inline">\(1\)</span>，否则为 <span class="math inline">\(0\)</span>；<span class="math inline">\(x_i\)</span> 是第 <span class="math inline">\(i\)</span> 个特征的值。</p>
<h2 id="deep-cross">Deep &amp; Cross</h2>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/deep_cross_architecture.png" id="fig:deep_cross_architecture" style="width:60.0%" alt="图 8: Deep &amp; Cross 架构[6]" /><figcaption aria-hidden="true">图 8: Deep &amp; Cross 架构<span class="citation" data-cites="wang2017deep"><sup>[<a href="#ref-wang2017deep" role="doc-biblioref">6</a>]</sup></span></figcaption>
</figure>
<p>Cross 网络的运算为：</p>
<p><span id="eq:deep_cross_cross"><span class="math display">\[\v{x}_{l+1} = \v{x}_0\T{\v{x}_l}\v{w}_l + \v{b}_l + \v{x}_l\qquad(19)\]</span></span></p>
<h2 id="fnn">FNN</h2>
<p>用 FM 的隐向量初始化 Embedding 层。</p>
<p>为什么 Embedding 层收敛速度较慢？</p>
<ul>
<li>Embedding 参数多</li>
<li>输入向量稀疏</li>
</ul>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/fnn_architecture.png" id="fig:fnn_architecture" alt="图 9: FNN 架构[7]" /><figcaption aria-hidden="true">图 9: FNN 架构<span class="citation" data-cites="zhang2016deep"><sup>[<a href="#ref-zhang2016deep" role="doc-biblioref">7</a>]</sup></span></figcaption>
</figure>
<p>其中，<span class="math inline">\(\v{w}\)</span> 和 <span class="math inline">\(\v{v}\)</span> 对应于 FM 中的参数：</p>
<p><span id="eq:fm_output"><span class="math display">\[\hat{\v{y}} = \sigmoid\left(w_0 + \sum_{i=1}^N w_i x_i +
\sum_{i=1}^N\sum_{j=i+1}^N\langle\v{v}_i,\v{v}_j\rangle x_i x_j\right)
\qquad(20)\]</span></span></p>
<h2 id="deepfm">DeepFM</h2>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/deep_fm_architecture.png" id="fig:deep_fm_architecture" alt="图 10: DeepFM 架构[8]" /><figcaption aria-hidden="true">图 10: DeepFM 架构<span class="citation" data-cites="guo2017deepfm"><sup>[<a href="#ref-guo2017deepfm" role="doc-biblioref">8</a>]</sup></span></figcaption>
</figure>
<h2 id="nfm">NFM</h2>
<p>用神经网络代替 FM 的二阶特征交叉。</p>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/nfm_architecture.png" id="fig:nfm_architecture" alt="图 11: NFM 架构[9]" /><figcaption aria-hidden="true">图 11: NFM 架构<span class="citation" data-cites="he2017nfm"><sup>[<a href="#ref-he2017nfm" role="doc-biblioref">9</a>]</sup></span></figcaption>
</figure>
<p>Bi-Interaction Pooling 具体操作为：</p>
<p><span id="eq:nfm_bi"><span class="math display">\[f_{\mathrm{BI}}(\mathcal{V}_x) = \sum_{i=1}^n\sum_{j=i+1}^n x_i\v{v}_i\odot
x_j\v{v}_j\qquad(21)\]</span></span></p>
<p>其中，<span class="math inline">\(\mathcal{V}_x\)</span> 是 Embedding 集合。</p>
<h2 id="afm">AFM</h2>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/afm_architecture.png" id="fig:afm_architecture" alt="图 12: AFM 架构[10]" /><figcaption aria-hidden="true">图 12: AFM 架构<span class="citation" data-cites="xiao2017attentional"><sup>[<a href="#ref-xiao2017attentional" role="doc-biblioref">10</a>]</sup></span></figcaption>
</figure>
<p>特征交叉采用元素积：</p>
<p><span id="eq:afm_pi"><span class="math display">\[f_{\mathrm{PI}}(\mathcal{E}) = \{(\v{v}_i\odot\v{v}_j) x_i x_j\mid
(i,j)\in\mathcal{R}_x\}\qquad(22)\]</span></span></p>
<p>其中，PI 表示 Pair-wise Interaction Layer；<span class="math inline">\(\mathcal{E} = \{\v{v}_i x_i\mid i\in\mathcal{X}\}\)</span>；<span class="math inline">\(\mathcal{X}\)</span> 为非零特征的索引集合；<span class="math inline">\(\mathcal{R}_x = \{(i,j)\mid i\in\mathcal{X}, j\in\mathcal{X}, j&gt;i\}\)</span>。</p>
<p><span id="eq:afm_att"><span class="math display">\[
\begin{align}
f_{\mathrm{Att}}(f_{\mathrm{PI}}(\mathcal{E})) &amp;= \sum_{(i,j)\in\mathcal{R}_x}
a_{ij}(\v{v}_i\odot\v{v}_j) x_i x_j \\
a_{ij} &amp;= \frac{\exp(a&#39;_{ij})}{\sum_{(i,j)\in\mathcal{R}_x}\exp(a&#39;_{ij})} \\
a&#39;_{ij} &amp;= \T{\v{h}}\ReLU(\m{W}(\v{v}_i\odot\v{v}_j)x_i x_j +\v{b})
\end{align}
\qquad(23)\]</span></span></p>
<h2 id="din">DIN</h2>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/din_architecture.png" id="fig:din_architecture" alt="图 13: DIN 架构[11]" /><figcaption aria-hidden="true">图 13: DIN 架构<span class="citation" data-cites="zhou2018deep"><sup>[<a href="#ref-zhou2018deep" role="doc-biblioref">11</a>]</sup></span></figcaption>
</figure>
<h3 id="注意力">注意力</h3>
<p><span id="eq:din_attention"><span class="math display">\[\v{v}_U(A) = f(\v{v}_A,\v{e}_1,\v{e}_2,\dots,\v{e}_H)
= \sum_{j=1}^H a(\v{e}_j,\v{v}_A)\v{e}_j
= \sum_{j=1}^H w_j\v{e}_j\qquad(24)\]</span></span></p>
<p>其中，<span class="math inline">\(\{\v{e}_1,\v{e}_2,\dots,\v{e}_H\}\)</span> 是用户 U 的历史行为的 Embedding 向量； <span class="math inline">\(\v{v}_A\)</span> 是广告 A 的 Embedding 向量。</p>
<h2 id="dien">DIEN</h2>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/dien_architecture.png" id="fig:dien_architecture" alt="图 14: DIEN 架构[12]" /><figcaption aria-hidden="true">图 14: DIEN 架构<span class="citation" data-cites="zhou2019deep"><sup>[<a href="#ref-zhou2019deep" role="doc-biblioref">12</a>]</sup></span></figcaption>
</figure>
<h3 id="augru">AUGRU</h3>
<p>AUGRU 改变了更新门：</p>
<p><span id="eq:dien_update_gate"><span class="math display">\[\tilde{\v{u}}&#39;_t = a_t\v{u}&#39;_t\qquad(25)\]</span></span></p>
<h2 id="drn">DRN</h2>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/drn_deep_reinforcement_recommendation_system.png" id="fig:drn_deep_reinforcement_recommendation_system" alt="图 15: 深度强化学习推荐系统[13]" /><figcaption aria-hidden="true">图 15: 深度强化学习推荐系统<span class="citation" data-cites="zheng2018drn"><sup>[<a href="#ref-zheng2018drn" role="doc-biblioref">13</a>]</sup></span></figcaption>
</figure>
<ul>
<li>State representation 为用户特征，Action representation 为候选新闻特征</li>
<li>用户向 Agent 请求新闻列表，Agent 根据 State representation 和 Action representation 选择最好的 Action 返回给用户，并获取用户反馈</li>
<li>Action 和反馈日志会存入 Agent 的内存，Agent 每小时会利用内存中的日志更新推荐算法</li>
</ul>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/drn_q.png" id="fig:drn_q" style="width:60.0%" alt="图 16: DRN Q 网络[13]" /><figcaption aria-hidden="true">图 16: DRN Q 网络<span class="citation" data-cites="zheng2018drn"><sup>[<a href="#ref-zheng2018drn" role="doc-biblioref">13</a>]</sup></span></figcaption>
</figure>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/drn_model_framework.png" id="fig:drn_model_framework" alt="图 17: DRN 模型框架[13]" /><figcaption aria-hidden="true">图 17: DRN 模型框架<span class="citation" data-cites="zheng2018drn"><sup>[<a href="#ref-zheng2018drn" role="doc-biblioref">13</a>]</sup></span></figcaption>
</figure>
<h3 id="竞争梯度下降法">竞争梯度下降法</h3>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/drn_dueling_bandit_gradient_descent.png" id="fig:drn_dueling_bandit_gradient_descent" style="width:60.0%" alt="图 18: 竞争梯度下降法[13]" /><figcaption aria-hidden="true">图 18: 竞争梯度下降法<span class="citation" data-cites="zheng2018drn"><sup>[<a href="#ref-zheng2018drn" role="doc-biblioref">13</a>]</sup></span></figcaption>
</figure>
<p><span id="eq:drn_delta_w"><span class="math display">\[\Delta\m{W} = \alpha\cdot\rand(-1,1)\cdot\m{W}\qquad(26)\]</span></span></p>
<p>其中，<span class="math inline">\(\alpha\)</span> 是探索因子。</p>
<h1 id="embedding">Embedding</h1>
<h2 id="不同-embedding-的优缺点">不同 Embedding 的优缺点</h2>
<div id="tbl:embedding_pros_cons">
<table>
<caption>表 3: 不同 Embedding 的优缺点</caption>
<thead>
<tr class="header">
<th>Embedding</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Word2vec</td>
<td>奠基</td>
<td></td>
</tr>
<tr class="even">
<td>Item2vec</td>
<td>没有时间窗口</td>
<td>只有序列型结构</td>
</tr>
<tr class="odd">
<td>EGES</td>
<td>缓解冷启动</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<h2 id="word2vec">Word2vec</h2>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/word2vec_architecture.png" id="fig:word2vec_architecture" style="width:80.0%" alt="图 19: CBOW 与 Skip-gram 架构[14]" /><figcaption aria-hidden="true">图 19: CBOW 与 Skip-gram 架构<span class="citation" data-cites="mikolov2013efficient"><sup>[<a href="#ref-mikolov2013efficient" role="doc-biblioref">14</a>]</sup></span></figcaption>
</figure>
<ul>
<li>根据经验，Skip-gram 的效果更好</li>
</ul>
<h3 id="基本结构">基本结构</h3>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/word2vec_base_net.png" id="fig:word2vec_base_net" style="width:60.0%" alt="图 20: word2vec 基本网络结构[15]" /><figcaption aria-hidden="true">图 20: word2vec 基本网络结构<span class="citation" data-cites="rong2014word2vec"><sup>[<a href="#ref-rong2014word2vec" role="doc-biblioref">15</a>]</sup></span></figcaption>
</figure>
<h4 id="输出-3">输出</h4>
<p><span id="eq:word2vec_base_output"><span class="math display">\[y_j = p(w_j\mid w_I)
= \frac{\exp(\T{\v{v}&#39;_{w_j}}\v{v}_{w_I})}{\sum_{j&#39;=1}^V\exp(\T{\v{v}&#39;_{w_{j&#39;}}}\v{v}_{w_I})}
\qquad(27)\]</span></span></p>
<p>其中，<span class="math inline">\(\v{v}_{w_I}\in\R^{N\times 1}\)</span> 为 <span class="math inline">\(\m{W}\)</span> 的第 <span class="math inline">\(I\)</span> 行； <span class="math inline">\(\v{v}&#39;_{w_j}\in\R^{N\times 1}\)</span> 为 <span class="math inline">\(\m{W}&#39;\)</span> 的第 <span class="math inline">\(j\)</span> 列。<span class="math inline">\(\m{W}\)</span> 为词向量矩阵。</p>
<h4 id="损失函数-2">损失函数</h4>
<p><span id="eq:word2vec_base_loss"><span class="math display">\[L = -\log p(w_O\mid w_I)\qquad(28)\]</span></span></p>
<p>其中，<span class="math inline">\(O\)</span> 为输出单词的索引；这个损失可以看做最大似然概率，也可以看做交叉熵。</p>
<h4 id="负采样">负采样</h4>
<p><span id="eq:word2vec_negative_sample"><span class="math display">\[L = -\log \sigma(\T{\v{v}&#39;_{w_O}}\v{h})
- \sum_{w_j\in\mathcal{W}_{\mathrm{neg}}}\log\sigma(-\T{\v{v}&#39;_{w_j}}\v{h})
\qquad(29)\]</span></span></p>
<p>其中，<span class="math inline">\(w_O\)</span> 是输出单词；<span class="math inline">\(\mathcal{W}_{\mathrm{neg}} = \{w_j\mid j=1,\cdots,K\}\)</span> 是采样得到的负样本集合。</p>
<h2 id="item2vec">Item2vec</h2>
<h2 id="deepwalk">DeepWalk</h2>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/deep_walk_architecture.png" id="fig:deep_walk_architecture" alt="图 21: DeepWalk 架构[16]" /><figcaption aria-hidden="true">图 21: DeepWalk 架构<span class="citation" data-cites="wang2018billion"><sup>[<a href="#ref-wang2018billion" role="doc-biblioref">16</a>]</sup></span></figcaption>
</figure>
<h3 id="随机游走的转移概率wang2018billion">随机游走的转移概率<span class="citation" data-cites="wang2018billion"><sup>[<a href="#ref-wang2018billion" role="doc-biblioref">16</a>]</sup></span></h3>
<p><span class="math display">\[
P(v_j\mid v_i) =
\begin{cases}
\frac{M_{ij}}{\sum_{j&#39;\in N_+(v_i)}M_{ij&#39;}}, &amp;\mathrm{if}\;v_j\in N_+(v_i)\\
0, &amp;\mathrm{if}\;e_{ij}\notin\mathcal{E}
\end{cases}
\]</span></p>
<p>其中，<span class="math inline">\(N_+(v_i)\)</span> 表示 <span class="math inline">\(v_i\)</span> 的出边集合；<span class="math inline">\(M_{ij}\)</span> 表示节点 <span class="math inline">\(i\)</span> 到节点 <span class="math inline">\(j\)</span> 边的权重；<span class="math inline">\(\mathcal{E}\)</span> 表示所有边的集合。</p>
<h2 id="node2vec">node2vec</h2>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/node2vec_bfs_dfs.png" id="fig:node2vec_bfs_dfs" style="width:60.0%" alt="图 22: node2vec 广度优先搜索与深度优先搜索[17]" /><figcaption aria-hidden="true">图 22: node2vec 广度优先搜索与深度优先搜索<span class="citation" data-cites="grover2016node2vec"><sup>[<a href="#ref-grover2016node2vec" role="doc-biblioref">17</a>]</sup></span></figcaption>
</figure>
<ul>
<li>同质性：图. 22 中的 <span class="math inline">\(u\)</span> 与 <span class="math inline">\(s_1\)</span> 属于同一社区，Embedding 应该相似</li>
<li>同构性：图. 22 中的 <span class="math inline">\(u\)</span> 与 <span class="math inline">\(s_6\)</span> 扮演相似的结构角色， Embedding 应该相似</li>
<li>BFS 能发现同构性；DFS 能发现同质性</li>
</ul>
<h3 id="跳转概率">跳转概率</h3>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/node2vec_transition.png" id="fig:node2vec_transition" style="width:60.0%" alt="图 23: node2vec 跳转概率[17]" /><figcaption aria-hidden="true">图 23: node2vec 跳转概率<span class="citation" data-cites="grover2016node2vec"><sup>[<a href="#ref-grover2016node2vec" role="doc-biblioref">17</a>]</sup></span></figcaption>
</figure>
<p>未归一化的跳转概率为：</p>
<p><span id="eq:node2vec_transition"><span class="math display">\[\pi_{vx} = \alpha_{pq}(t,x)\cdot w_{vx}\qquad(30)\]</span></span></p>
<p>其中，</p>
<p><span id="eq:node2vec_alpha"><span class="math display">\[
\alpha_{pq}(t,x) =
\begin{cases}
\frac{1}{p}\quad &amp;\mathrm{if}\;d_{tx} = 0\\
1 &amp;\mathrm{if}\;d_{tx} = 1\\
\frac{1}{q}\quad &amp;\mathrm{if}\;d_{tx} = 2
\end{cases}
\qquad(31)\]</span></span></p>
<p><span class="math inline">\(t\)</span> 为上一个节点；<span class="math inline">\(w_{vx}\)</span> 是边 <span class="math inline">\(vx\)</span> 的权重；<span class="math inline">\(d_{tx}\)</span> 表示节点 <span class="math inline">\(t\)</span> 与节点 <span class="math inline">\(x\)</span> 的最短距离；<span class="math inline">\(p\)</span> 为返回参数；<span class="math inline">\(q\)</span> 为进出参数。</p>
<h2 id="eges">EGES</h2>
<figure>
<img src="https://kaizhang91.github.io/note/fig/AI/推荐系统/eges_architecture.png" id="fig:eges_architecture" style="width:60.0%" alt="图 24: EGES 架构[16]" /><figcaption aria-hidden="true">图 24: EGES 架构<span class="citation" data-cites="wang2018billion"><sup>[<a href="#ref-wang2018billion" role="doc-biblioref">16</a>]</sup></span></figcaption>
</figure>
<h3 id="隐层向量">隐层向量</h3>
<p><span class="math display">\[\m{H}_v = \frac{\sum_{j=0}^n \e^{a_v^j}\m{W}_v^j}{\sum_{j=0}^n \e^{a_v^j}}\]</span></p>
<p>使用 <span class="math inline">\(e^{a_v^j}\)</span> 作为权重是想让权重总是大于 <span class="math inline">\(0\)</span>。</p>
<h2 id="局部敏感哈希">局部敏感哈希</h2>
<p>欧式空间中，将高维空间的点映射到低维空间：</p>
<ul>
<li>原本相近的点在低维空间肯定依然相近</li>
<li>原本远离的点则有一定概率变成相近的点</li>
</ul>
<p><span id="eq:lsh_hash"><span class="math display">\[h^{\v{x},b} = \left\lfloor\frac{\v{v}\cdot\v{x} + b}{w}\right\rfloor\qquad(32)\]</span></span></p>
<h1 id="特征工程">特征工程</h1>
<h2 id="原则">原则</h2>
<ul>
<li>尽可能暴露有用信息</li>
<li>尽量摈弃冗余信息</li>
</ul>
<h1 id="召回策略">召回策略</h1>
<div id="tbl:recall_sort">
<table>
<caption>表 4: 召回层与排序层</caption>
<thead>
<tr class="header">
<th>层</th>
<th>目标</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>召回层</td>
<td>尽量让用户感兴趣的物品被快速召回</td>
<td>候选集合大、速度快、模型简单、特征较少</td>
</tr>
<tr class="even">
<td>排序层</td>
<td>得到精准的排序结果</td>
<td>候选集合小、模型复杂、特征较多</td>
</tr>
</tbody>
</table>
</div>
<h1 id="冷启动的解决办法">冷启动的解决办法</h1>
<h2 id="基于规则的冷启动">基于规则的冷启动</h2>
<h2 id="丰富冷启动过程中可获得的用户和物品特征">丰富冷启动过程中可获得的用户和物品特征</h2>
<ul>
<li>用户的注册信息</li>
<li>第三方 DMP 提供的用户信息</li>
<li>物品的内容特征</li>
<li>引导用户输入的冷启动特征</li>
</ul>
<h2 id="利用主动学习迁移学习和探索与利用机制">利用主动学习、迁移学习和“探索与利用”机制</h2>
<h3 id="探索与利用机制">“探索与利用”机制</h3>
<p>UCB (Upper Confidence Bound，置信区间上界)：</p>
<p><span id="eq:ucb"><span class="math display">\[\mathrm{UCB}(j) = \mean{x_j}+\sqrt{\frac{2\ln n}{n_j}}\qquad(33)\]</span></span></p>
<p>其中，<span class="math inline">\(\mean{x_j}\)</span> 为第 <span class="math inline">\(j\)</span> 个物品的平均回报；<span class="math inline">\(n_j\)</span> 为第 <span class="math inline">\(j\)</span> 个物品的曝光次数； <span class="math inline">\(n\)</span> 为所有物品的曝光次数。可以看到，UCB 倾向于推荐冷启动的物品。</p>
<h1 id="推荐模型离线训练">推荐模型离线训练</h1>
<h2 id="spark-mlib">Spark MLib</h2>
<h2 id="parameter-server">Parameter Server</h2>
<ul>
<li>分布式梯度下降策略：同步阻断 -&gt; 异步非阻断</li>
<li>多 server</li>
<li>使用一致性哈希、参数范围拉取、参数范围推送，减小带宽</li>
</ul>
<h1 id="推荐系统的评估">推荐系统的评估</h1>
<h2 id="holdout-检验">Holdout 检验</h2>
<h2 id="k-fold-交叉验证">K-fold 交叉验证</h2>
<p>把 K 次评估指标的平均值作为最终的评估指标。</p>
<h1 class="unnumbered" id="参考文献">参考文献</h1>
<div id="refs" class="references" role="doc-bibliography">
<div id="ref-sedhain2015autorec">
<p>[1] SEDHAIN S, MENON A K, SANNER S, 等. Autorec: Autoencoders meet collaborative filtering[C]//Proceedings of the 24th international conference on World Wide Web..</p>
</div>
<div id="ref-shan2016deep">
<p>[2] SHAN Y, HOENS T R, JIAO J, 等. Deep crossing: Web-scale modeling without manually crafted combinatorial features[C]//Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining..</p>
</div>
<div id="ref-he2017neural">
<p>[3] HE X, LIAO L, ZHANG H, 等. Neural collaborative filtering[C]//Proceedings of the 26th international conference on world wide web..</p>
</div>
<div id="ref-qu2016product">
<p>[4] QU Y, CAI H, REN K, 等. Product-based neural networks for user response prediction[C]//2016 IEEE 16th International Conference on Data Mining (ICDM). IEEE, 2016: 1149–1154.</p>
</div>
<div id="ref-cheng2016wide">
<p>[5] CHENG H-T, KOC L, HARMSEN J, 等. Wide &amp; deep learning for recommender systems[C]//Proceedings of the 1st workshop on deep learning for recommender systems..</p>
</div>
<div id="ref-wang2017deep">
<p>[6] WANG R, FU B, FU G, 等. Deep &amp; cross network for ad click predictions[M]//Proceedings of the ADKDD’17..</p>
</div>
<div id="ref-zhang2016deep">
<p>[7] ZHANG W, DU T, WANG J. Deep learning over multi-field categorical data[C]//European conference on information retrieval. Springer, 2016: 45–57.</p>
</div>
<div id="ref-guo2017deepfm">
<p>[8] GUO H, TANG R, YE Y, 等. DeepFM: a factorization-machine based neural network for CTR prediction[J]. arXiv preprint arXiv:1703.04247, 2017.</p>
</div>
<div id="ref-he2017nfm">
<p>[9] HE X, CHUA T-S. Neural factorization machines for sparse predictive analytics[C]//Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval..</p>
</div>
<div id="ref-xiao2017attentional">
<p>[10] XIAO J, YE H, HE X, 等. Attentional factorization machines: Learning the weight of feature interactions via attention networks[J]. arXiv preprint arXiv:1708.04617, 2017.</p>
</div>
<div id="ref-zhou2018deep">
<p>[11] ZHOU G, ZHU X, SONG C, 等. Deep interest network for click-through rate prediction[C]//Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining..</p>
</div>
<div id="ref-zhou2019deep">
<p>[12] ZHOU G, MOU N, FAN Y, 等. Deep interest evolution network for click-through rate prediction[C]//Proceedings of the AAAI conference on artificial intelligence..</p>
</div>
<div id="ref-zheng2018drn">
<p>[13] ZHENG G, ZHANG F, ZHENG Z, 等. DRN: A deep reinforcement learning framework for news recommendation[C]//Proceedings of the 2018 World Wide Web Conference..</p>
</div>
<div id="ref-mikolov2013efficient">
<p>[14] MIKOLOV T, CHEN K, CORRADO G, 等. Efficient estimation of word representations in vector space[J]. arXiv preprint arXiv:1301.3781, 2013.</p>
</div>
<div id="ref-rong2014word2vec">
<p>[15] RONG X. word2vec parameter learning explained[J]. arXiv preprint arXiv:1411.2738, 2014.</p>
</div>
<div id="ref-wang2018billion">
<p>[16] WANG J, HUANG P, ZHAO H, 等. Billion-scale commodity embedding for e-commerce recommendation in alibaba[C]//Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining..</p>
</div>
<div id="ref-grover2016node2vec">
<p>[17] GROVER A, LESKOVEC J. node2vec: Scalable feature learning for networks[C]//Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining..</p>
</div>
</div>

<nav id="TableOfContents" role="doc-toc">
  <h2 id="toc-title">目录</h2>
  <ul>
  <li><a href="#术语">术语</a></li>
  <li><a href="#架构">架构</a></li>
  <li><a href="#算法">算法</a>
  <ul>
  <li><a href="#不同算法的优缺点">不同算法的优缺点</a></li>
  <li><a href="#协同过滤">协同过滤</a>
  <ul>
  <li><a href="#共现矩阵">共现矩阵</a></li>
  <li><a href="#相似度">相似度</a></li>
  <li><a href="#usercf">UserCF</a></li>
  <li><a href="#itemcf">ItemCF</a></li>
  </ul></li>
  <li><a href="#矩阵分解">矩阵分解</a>
  <ul>
  <li><a href="#奇异值分解">奇异值分解</a></li>
  <li><a href="#梯度下降">梯度下降</a></li>
  <li><a href="#消除用户和物品打分的偏差">消除用户和物品打分的偏差</a></li>
  </ul></li>
  <li><a href="#逻辑回归">逻辑回归</a>
  <ul>
  <li><a href="#输出">输出</a></li>
  <li><a href="#损失函数">损失函数</a></li>
  </ul></li>
  <li><a href="#fm---ffm">FM -&gt; FFM</a>
  <ul>
  <li><a href="#poly2">POLY2</a></li>
  <li><a href="#fm">FM</a></li>
  <li><a href="#ffm">FFM</a></li>
  </ul></li>
  <li><a href="#gbdt-lr">GBDT + LR</a></li>
  <li><a href="#ls-plm">LS-PLM</a>
  <ul>
  <li><a href="#输出-1">输出</a></li>
  </ul></li>
  <li><a href="#autorec">AutoRec</a>
  <ul>
  <li><a href="#损失函数-1">损失函数</a></li>
  <li><a href="#重建函数">重建函数</a></li>
  <li><a href="#输出-2">输出</a></li>
  </ul></li>
  <li><a href="#deep-crossing">Deep Crossing</a>
  <ul>
  <li><a href="#残差神经网络">残差神经网络</a></li>
  </ul></li>
  <li><a href="#neuralcf">NeuralCF</a></li>
  <li><a href="#pnn">PNN</a></li>
  <li><a href="#wide-deep">Wide &amp; Deep</a></li>
  <li><a href="#deep-cross">Deep &amp; Cross</a></li>
  <li><a href="#fnn">FNN</a></li>
  <li><a href="#deepfm">DeepFM</a></li>
  <li><a href="#nfm">NFM</a></li>
  <li><a href="#afm">AFM</a></li>
  <li><a href="#din">DIN</a>
  <ul>
  <li><a href="#注意力">注意力</a></li>
  </ul></li>
  <li><a href="#dien">DIEN</a>
  <ul>
  <li><a href="#augru">AUGRU</a></li>
  </ul></li>
  <li><a href="#drn">DRN</a>
  <ul>
  <li><a href="#竞争梯度下降法">竞争梯度下降法</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#embedding">Embedding</a>
  <ul>
  <li><a href="#不同-embedding-的优缺点">不同 Embedding 的优缺点</a></li>
  <li><a href="#word2vec">Word2vec</a>
  <ul>
  <li><a href="#基本结构">基本结构</a></li>
  </ul></li>
  <li><a href="#item2vec">Item2vec</a></li>
  <li><a href="#deepwalk">DeepWalk</a>
  <ul>
  <li><a href="#随机游走的转移概率wang2018billion">随机游走的转移概率<span class="citation" data-cites="wang2018billion"><sup>[<span>16</span>]</sup></span></a></li>
  </ul></li>
  <li><a href="#node2vec">node2vec</a>
  <ul>
  <li><a href="#跳转概率">跳转概率</a></li>
  </ul></li>
  <li><a href="#eges">EGES</a>
  <ul>
  <li><a href="#隐层向量">隐层向量</a></li>
  </ul></li>
  <li><a href="#局部敏感哈希">局部敏感哈希</a></li>
  </ul></li>
  <li><a href="#特征工程">特征工程</a>
  <ul>
  <li><a href="#原则">原则</a></li>
  </ul></li>
  <li><a href="#召回策略">召回策略</a></li>
  <li><a href="#冷启动的解决办法">冷启动的解决办法</a>
  <ul>
  <li><a href="#基于规则的冷启动">基于规则的冷启动</a></li>
  <li><a href="#丰富冷启动过程中可获得的用户和物品特征">丰富冷启动过程中可获得的用户和物品特征</a></li>
  <li><a href="#利用主动学习迁移学习和探索与利用机制">利用主动学习、迁移学习和“探索与利用”机制</a>
  <ul>
  <li><a href="#探索与利用机制">“探索与利用”机制</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#推荐模型离线训练">推荐模型离线训练</a>
  <ul>
  <li><a href="#spark-mlib">Spark MLib</a></li>
  <li><a href="#parameter-server">Parameter Server</a></li>
  </ul></li>
  <li><a href="#推荐系统的评估">推荐系统的评估</a>
  <ul>
  <li><a href="#holdout-检验">Holdout 检验</a></li>
  <li><a href="#k-fold-交叉验证">K-fold 交叉验证</a></li>
  </ul></li>
  <li><a href="#参考文献">参考文献</a></li>
  </ul>
</nav>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>

 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      
  

 
    </aside>
    
  </main>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>

<script>
  
  const tableOfContents = document.getElementById("TableOfContents");
  const tableOfContents1 = tableOfContents.cloneNode(true);
  document.querySelector(".book-toc").appendChild(tableOfContents);
  document.querySelector(".book-header > aside").appendChild(tableOfContents1);

  
  const searchResults = document.getElementById("book-search-results");
  document
    .getElementById("book-search-input")
    .addEventListener("keyup", (event) => {
      
      
      if (event.keyCode === 13) {
        event.preventDefault();
        if (searchResults.childNodes.length > 0) {
          const searchResult = searchResults.childNodes[0].childNodes[0];
          window.location.href = searchResult.href;
        }
      }
    });

  
  MathJax = {
    tex: {
      macros: {
        argmin: ["\\mathop{\\arg\\,\\min}"],
        AveP: ["\\mathrm{AveP}"],
        bm: ["{\\boldsymbol{#1}}", 1],
        cos: ["\\mathrm{cos}"],
        d: ["\\mathrm{d}"],
        data: ["\\mathrm{data}"],
        diag: ["\\mathrm{diag}"],
        e: ["\\mathrm{e}"],
        FN: ["\\mathrm{FN}"],
        FP: ["\\mathrm{FP}"],
        FPR: ["\\mathrm{FPR}"],
        log: ["\\mathrm{log}\\,"],
        MAP: ["\\mathrm{MAP}"],
        m: ["{\\bm{\\mathrm{#1}}}", 1],
        mean: ["{\\overline{#1}}", 1],
        median: ["\\mathrm{median}"],
        model: ["\\mathrm{model}"],
        R: ["\\mathbb{R}"],
        rand: ["\\mathrm{rand}"],
        rel: ["\\mathrm{rel}"],
        ReLU: ["\\mathrm{ReLU}"],
        set: ["{\\mathbb{#1}}", 1],
        sigmoid: ["\\mathrm{sigmoid}"],
        sign: ["\\mathrm{sign}"],
        sim: ["\\mathrm{sim}"],
        SNR: ["\\mathrm{SNR}"],
        SO: ["\\mathrm{SO}"],
        tanh: ["\\mathrm{tanh}"],
        TN: ["\\mathrm{TN}"],
        TP: ["\\mathrm{TP}"],
        TPR: ["\\mathrm{TPR}"],
        transformation: ["{\\mathcal{#1}}", 1],
        T: ["{#1}^{\\mathsf{T}}", 1],
        v: ["{\\bm{\\mathrm{#1}}}", 1],
      },
    },
  };

  
  hljs.initHighlightingOnLoad();
  

</script>


<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
></script>




</body>

</html>












