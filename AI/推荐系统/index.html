<!DOCTYPE html>
<html lang="cn" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="1 术语  表 1: 术语  缩写 全称 含义    C Context 场景  CTR Click Through Rate 点击率  CVR Conversion Rate 转化率  DMP Data Management Platform 数据管理平台  FFM Field-aware Factorization Machine 域感知因子分解机  FM Factorization Machine 因子分解机  I Item 物品  MLP Multilayer Perception 多层感知机  U User 用户     2 架构  图 1: 推荐系统架构  3 算法 3.">
<meta name="theme-color" content="#FFFFFF"><meta property="og:title" content="推荐系统" />
<meta property="og:description" content="1 术语  表 1: 术语  缩写 全称 含义    C Context 场景  CTR Click Through Rate 点击率  CVR Conversion Rate 转化率  DMP Data Management Platform 数据管理平台  FFM Field-aware Factorization Machine 域感知因子分解机  FM Factorization Machine 因子分解机  I Item 物品  MLP Multilayer Perception 多层感知机  U User 用户     2 架构  图 1: 推荐系统架构  3 算法 3." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://kaizhang16.github.io/note/AI/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/" /><meta property="article:section" content="AI" />



<title>推荐系统 | 凯的笔记</title>
<link rel="manifest" href="/note/manifest.json">
<link rel="icon" href="/note/favicon.png" type="image/x-icon">
<link rel="stylesheet" href="/note/book.min.34c9a047c1f27a4b55389b94cd3f2fb1df24a54da7c6c83eaf62cced820bf578.css" integrity="sha256-NMmgR8HyektVOJuUzT8vsd8kpU2nxsg&#43;r2LM7YIL9Xg=">
<script defer src="/note/cn.search.min.5d40e9b5d7c4cea84be2561b275cf4f99d5587258bede8789afef7b0d6916218.js" integrity="sha256-XUDptdfEzqhL4lYbJ1z0&#43;Z1VhyWL7eh4mv73sNaRYhg="></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->

  
<link rel="icon" href="/note/favicon.ico" type="image/x-icon">


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.4.1/styles/dark.min.css">




</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a href="/note"><span>凯的笔记</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="搜索" aria-label="搜索" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>











  

  



  
  <ul>
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-cfbd43d7dbc20d8fbe7979a2801e3144" class="toggle" checked />
    <label for="section-cfbd43d7dbc20d8fbe7979a2801e3144" class="flex justify-between">
      <a  class="">AI</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/AI/QA/" class="">QA</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/AI/dev_env/" class="">开发环境</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/AI/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/" class=" active">推荐系统</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/AI/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="">机器学习</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/AI/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="">深度学习</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/AI/%E9%A1%B9%E7%9B%AE/" class="">项目</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-4af17239608ef6224ba6d5135a065aee" class="toggle"  />
    <label for="section-4af17239608ef6224ba6d5135a065aee" class="flex justify-between">
      <a  class="">CS</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/CS/http/" class="">HTTP</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/CS/Linux/" class="">Linux</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/CS/oauth2/" class="">OAuth 2</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/CS/transmission/" class="">传输</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/CS/compress/" class="">压缩</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/CS/security/" class="">安全</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/CS/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/" class="">持续集成</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/CS/%E6%95%B0%E6%8D%AE%E5%BA%93/" class="">数据库</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/CS/data-type/" class="">数据类型</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/CS/%E7%AE%97%E6%B3%95/" class="">算法</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/CS/encoding/" class="">编码</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/CS/network/" class="">网络</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-817f67a0d4c538392ea74ac855517ffe" class="toggle"  />
    <label for="section-817f67a0d4c538392ea74ac855517ffe" class="flex justify-between">
      <a  class="">LeetCode</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/LeetCode/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" class="">动态规划</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/LeetCode/%E5%9B%9E%E6%BA%AF/" class="">回溯</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/LeetCode/%E5%AD%97%E7%AC%A6%E4%B8%B2/" class="">字符串</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/LeetCode/%E6%95%B0%E5%AD%97/" class="">数字</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/LeetCode/%E6%95%B0%E7%BB%84/" class="">数组</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/LeetCode/%E6%A0%91/" class="">树</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/LeetCode/%E6%A6%82%E7%8E%87%E8%AE%BA/" class="">概率论</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/LeetCode/%E9%93%BE%E8%A1%A8/" class="">链表</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-9bfe21a0187b525fe1f8c33e218fae99" class="toggle"  />
    <label for="section-9bfe21a0187b525fe1f8c33e218fae99" class="flex justify-between">
      <a  class="">NLP</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/NLP/GPT-2/" class="">GPT-2</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/NLP/LSTM_GRU/" class="">LSTM 与 GRU</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/NLP/Transformer/" class="">Transformer</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-70bdf8d87af46a79686d31378c1d7d85" class="toggle"  />
    <label for="section-70bdf8d87af46a79686d31378c1d7d85" class="flex justify-between">
      <a  class="">工具</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E5%B7%A5%E5%85%B7/git/" class="">Git</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E5%B7%A5%E5%85%B7/ipad/" class="">iPad</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E5%B7%A5%E5%85%B7/Linux/" class="">Linux</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E5%B7%A5%E5%85%B7/Windows/" class="">Windows</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E5%B7%A5%E5%85%B7/Word/" class="">Word</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E5%B7%A5%E5%85%B7/%E5%86%99%E4%BD%9C/" class="">写作</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E5%B7%A5%E5%85%B7/search/" class="">搜索</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E5%B7%A5%E5%85%B7/%E6%96%87%E7%8C%AE%E7%AE%A1%E7%90%86/" class="">文献管理</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E5%B7%A5%E5%85%B7/format/" class="">格式</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E5%B7%A5%E5%85%B7/%E6%B5%8F%E8%A7%88%E5%99%A8/" class="">浏览器</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E5%B7%A5%E5%85%B7/%E7%BC%96%E8%BE%91%E5%99%A8/" class="">编辑器</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E5%B7%A5%E5%85%B7/%E8%99%9A%E6%8B%9F%E6%9C%BA/" class="">虚拟机</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E5%B7%A5%E5%85%B7/project-management/" class="">项目管理</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1f9a426141100f8f7ab323c20cac8352" class="toggle"  />
    <label for="section-1f9a426141100f8f7ab323c20cac8352" class="flex justify-between">
      <a  class="">数学</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E6%95%B0%E5%AD%A6/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/" class="">线性代数</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E6%95%B0%E5%AD%A6/%E7%BB%9F%E8%AE%A1/" class="">统计</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-49cd3dd12728d4fd4ae01f7800801d13" class="toggle"  />
    <label for="section-49cd3dd12728d4fd4ae01f7800801d13" class="flex justify-between">
      <a  class="">编程</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E7%BC%96%E7%A8%8B/bash/" class="">Bash</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E7%BC%96%E7%A8%8B/c&#43;&#43;/" class="">C&#43;&#43;</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E7%BC%96%E7%A8%8B/css/" class="">CSS</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E7%BC%96%E7%A8%8B/dhall/" class="">Dhall</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E7%BC%96%E7%A8%8B/fish-shell/" class="">fish-shell</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E7%BC%96%E7%A8%8B/flutter/" class="">Flutter</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E7%BC%96%E7%A8%8B/golang/" class="">Golang</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E7%BC%96%E7%A8%8B/html/" class="">HTML</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E7%BC%96%E7%A8%8B/js/" class="">JavaScript</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E7%BC%96%E7%A8%8B/Pandoc/" class="">Pandoc</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E7%BC%96%E7%A8%8B/PowerShell/" class="">PowerShell</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E7%BC%96%E7%A8%8B/Python/" class="">Python</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E7%BC%96%E7%A8%8B/rust/" class="">Rust</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E7%BC%96%E7%A8%8B/TeX/" class="">TeX</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E7%BC%96%E7%A8%8B/toml/" class="">Toml</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E7%BC%96%E7%A8%8B/YAML/" class="">YAML</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E7%BC%96%E7%A8%8B/zsh/" class="">Zsh</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E7%BC%96%E7%A8%8B/template/" class="">模板</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-1e20c44ce142ce73dcb99537728dc9a3" class="toggle"  />
    <label for="section-1e20c44ce142ce73dcb99537728dc9a3" class="flex justify-between">
      <a  class="">视觉</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E8%A7%86%E8%A7%89/unity/" class="">Unity</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E8%A7%86%E8%A7%89/image/" class="">图像</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="https://kaizhang16.github.io/note/%E8%A7%86%E8%A7%89/video/" class="">视频</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>















</nav>




  <script>(function(){var a=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(b){localStorage.setItem("menu.scrollTop",a.scrollTop)}),a.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/note/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>推荐系统</strong>

  <label for="toc-control">
    
    <img src="/note/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  




  </aside>
  
 
      </header>

      
      
  <article class="markdown"><h1 data-number="1" id="术语"><span class="header-section-number">1</span> 术语</h1>
<div id="tbl:terminology">
<table>
<caption>表 1: 术语</caption>
<thead>
<tr class="header">
<th>缩写</th>
<th>全称</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>C</td>
<td>Context</td>
<td>场景</td>
</tr>
<tr class="even">
<td>CTR</td>
<td>Click Through Rate</td>
<td>点击率</td>
</tr>
<tr class="odd">
<td>CVR</td>
<td>Conversion Rate</td>
<td>转化率</td>
</tr>
<tr class="even">
<td>DMP</td>
<td>Data Management Platform</td>
<td>数据管理平台</td>
</tr>
<tr class="odd">
<td>FFM</td>
<td>Field-aware Factorization Machine</td>
<td>域感知因子分解机</td>
</tr>
<tr class="even">
<td>FM</td>
<td>Factorization Machine</td>
<td>因子分解机</td>
</tr>
<tr class="odd">
<td>I</td>
<td>Item</td>
<td>物品</td>
</tr>
<tr class="even">
<td>MLP</td>
<td>Multilayer Perception</td>
<td>多层感知机</td>
</tr>
<tr class="odd">
<td>U</td>
<td>User</td>
<td>用户</td>
</tr>
</tbody>
</table>
</div>
<h1 data-number="2" id="架构"><span class="header-section-number">2</span> 架构</h1>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/architecture.webp" id="fig:architecture" alt="图 1: 推荐系统架构" /><figcaption aria-hidden="true">图 1: 推荐系统架构</figcaption>
</figure>
<h1 data-number="3" id="算法"><span class="header-section-number">3</span> 算法</h1>
<h2 data-number="3.1" id="不同算法的优缺点"><span class="header-section-number">3.1</span> 不同算法的优缺点</h2>
<div id="tbl:algorithm_pros_cons">
<table>
<caption>表 2: 不同算法的优缺点</caption>
<thead>
<tr class="header">
<th>算法</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>UserCF</td>
<td>符合直觉（兴趣相似的朋友喜欢的物品，我也喜欢）</td>
<td>用户数远大于物品数</td>
</tr>
<tr class="even">
<td></td>
<td>社交特性更强，适于发现热点</td>
<td>用户历史数据向量很稀疏</td>
</tr>
<tr class="odd">
<td>ItemCF</td>
<td>适于兴趣变化较为稳定的应用</td>
<td>泛化能力弱，头部效应强</td>
</tr>
<tr class="even">
<td></td>
<td>直观，可解释性强</td>
<td>无法有效引入场景信息</td>
</tr>
<tr class="odd">
<td>矩阵分解</td>
<td>泛化能力强</td>
<td>不方便融合特征</td>
</tr>
<tr class="even">
<td></td>
<td>空间复杂度低</td>
<td>不好冷启动</td>
</tr>
<tr class="odd">
<td></td>
<td>便于与神经网络集成</td>
<td></td>
</tr>
<tr class="even">
<td>逻辑回归</td>
<td>融合多种特征</td>
<td>无法特征交叉、筛选</td>
</tr>
<tr class="odd">
<td></td>
<td>假设 <span class="math inline">\(y\)</span> 服从伯努利分布，有物理意义</td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>是各特征的加权和，可解释性强</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>易于并行化、模型简单、易于训练</td>
<td></td>
</tr>
<tr class="even">
<td>POLY2</td>
<td>特征交叉</td>
<td>特征向量更稀疏，不好训练</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td>参数增多</td>
</tr>
<tr class="even">
<td>FM</td>
<td>参数从 POLY2 的 <span class="math inline">\(n^2\)</span> 下降到 <span class="math inline">\(nk\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>比 POLY2 更适于稀疏数据，泛化能力强</td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>易于上线</td>
<td></td>
</tr>
<tr class="odd">
<td>FFM</td>
<td>比 FM 表达能力强</td>
<td>计算复杂度上升到 <span class="math inline">\(kn^2\)</span></td>
</tr>
<tr class="even">
<td>GBDT+LR</td>
<td>特征工程模型化</td>
<td></td>
</tr>
<tr class="odd">
<td>LS-PLM</td>
<td>能挖掘非线性模式</td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>引入 L1 惩罚，模型稀疏</td>
<td></td>
</tr>
<tr class="odd">
<td>AutoRec</td>
<td>第一次使用深度学习框架</td>
<td></td>
</tr>
<tr class="even">
<td>Deep Crossing</td>
<td>特征间深度交叉</td>
<td></td>
</tr>
<tr class="odd">
<td>NeuralCF</td>
<td>用户向量和物品向量更充分地交叉</td>
<td>没有引入更多特征</td>
</tr>
<tr class="even">
<td></td>
<td>表达能力比矩阵分解强</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>可以灵活选择互操作层</td>
<td></td>
</tr>
<tr class="even">
<td>PNN</td>
<td>强调不同特征之间的交互</td>
<td>简化操作丢失信息</td>
</tr>
<tr class="odd">
<td>Wide &amp; Deep</td>
<td>综合记忆能力和泛化能力</td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>开拓了融合不同网络结构的新思路</td>
<td></td>
</tr>
<tr class="odd">
<td>Deep &amp; Cross</td>
<td>Wide 部分的特征自动交叉</td>
<td></td>
</tr>
<tr class="even">
<td>DIEN</td>
<td>预测下一次购买，更符合业务目标</td>
<td>训练复杂度高</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td>串行推断</td>
</tr>
<tr class="even">
<td>DRN</td>
<td>变静态为动态，在线训练</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<h2 data-number="3.2" id="协同过滤"><span class="header-section-number">3.2</span> 协同过滤</h2>
<h3 data-number="3.2.1" id="共现矩阵"><span class="header-section-number">3.2.1</span> 共现矩阵</h3>
<p>用户为行坐标（记用户总数为 <span class="math inline">\(m\)</span>）、物品为列坐标（即物品总数为 <span class="math inline">\(n\)</span>）的 <span class="math inline">\(m\times n\)</span> 维矩阵。</p>
<h3 data-number="3.2.2" id="相似度"><span class="header-section-number">3.2.2</span> 相似度</h3>
<h4 data-number="3.2.2.1" id="余弦相似度"><span class="header-section-number">3.2.2.1</span> 余弦相似度</h4>
<p><span id="eq:cosine_similarity"><span class="math display">\[\sim(\v{i},\v{j}) = \cos(\v{i}, \v{j}) = \frac{\v{i}\cdot\v{j}}{\lVert\v{i}\rVert\cdot\lVert\v{j}\rVert}\qquad(1)\]</span></span></p>
<p>其中，<span class="math inline">\(\v{i}\)</span>、<span class="math inline">\(\v{j}\)</span> 均表示用户向量。</p>
<h4 data-number="3.2.2.2" id="皮尔逊相关系数"><span class="header-section-number">3.2.2.2</span> 皮尔逊相关系数</h4>
<p><span id="eq:pearsion_coefficient"><span class="math display">\[\sim(i,j) = \frac{\sum_{p\in P}(R_{i,p} - \mean{R_i})(R_{j,p}-\mean{R_j})}{\sqrt{\sum_{p\in P}(R_{i,p}-\mean{R_i})^2}\sqrt{\sum_{p\in P}(R_{j,p}-\mean{R_j})^2}}\qquad(2)\]</span></span></p>
<p>其中，<span class="math inline">\(R_{i,p}\)</span> 表示用户 <span class="math inline">\(i\)</span> 对物品 <span class="math inline">\(p\)</span> 的评分；<span class="math inline">\(\mean{R_i}\)</span> 表示用户 <span class="math inline">\(i\)</span> 对所有物品的平均评分；<span class="math inline">\(P\)</span> 代表所有物品的集合。</p>
<blockquote>
<p>皮尔逊相关系数减小了用户评分偏置的影响。</p>
</blockquote>
<h4 data-number="3.2.2.3" id="皮尔逊相关系数拓展"><span class="header-section-number">3.2.2.3</span> 皮尔逊相关系数拓展</h4>
<p><span id="eq:pearsion_coefficient_item"><span class="math display">\[\sim(i,j) = \frac{\sum_{p\in P}(R_{i,p} - \mean{R_p})(R_{j,p}-\mean{R_p})}{\sqrt{\sum_{p\in P}(R_{i,p}-\mean{R_p})^2}\sqrt{\sum_{p\in P}(R_{j,p}-\mean{R_p})^2}}\qquad(3)\]</span></span></p>
<p>其中，<span class="math inline">\(R_{i,p}\)</span> 表示用户 <span class="math inline">\(i\)</span> 对物品 <span class="math inline">\(p\)</span> 的评分；<span class="math inline">\(\mean{R_p}\)</span> 表示物品 <span class="math inline">\(p\)</span> 的平均评分；<span class="math inline">\(P\)</span> 代表所有物品的集合。</p>
<blockquote>
<p>式. 3 减小了物品评分偏置的影响。</p>
</blockquote>
<h3 data-number="3.2.3" id="usercf"><span class="header-section-number">3.2.3</span> UserCF</h3>
<p>基于用户的协同过滤。</p>
<p><span id="eq:user_cf"><span class="math display">\[R_{u,p} = \frac{\sum_{s\in S}w_{u,s}R_{s,p}}{\sum_{s\in S}w_{u,s}}\qquad(4)\]</span></span></p>
<p>其中，<span class="math inline">\(R_{s,p}\)</span> 表示用户 <span class="math inline">\(s\)</span> 对物品 <span class="math inline">\(p\)</span> 的评分；<span class="math inline">\(w_{u,s}\)</span> 表示用户 <span class="math inline">\(u\)</span> 与用户 <span class="math inline">\(s\)</span> 的相似度。</p>
<ul>
<li>根据用户向量找到 top n 相似用户</li>
<li>将相似用户对物品的评分加权平均，即可得到目标用户对物品的评分</li>
</ul>
<h3 data-number="3.2.4" id="itemcf"><span class="header-section-number">3.2.4</span> ItemCF</h3>
<p>基于物品相似度的协同过滤。</p>
<p><span id="eq:item_cf"><span class="math display">\[R_{u,p} = \sum_{h\in H}w_{p,h}R_{u,h}\qquad(5)\]</span></span></p>
<p>其中，<span class="math inline">\(R_{u,h}\)</span> 表示用户 <span class="math inline">\(u\)</span> 对物品 <span class="math inline">\(h\)</span> 的评分；<span class="math inline">\(w_{p,h}\)</span> 表示物品 <span class="math inline">\(p\)</span> 与物品 <span class="math inline">\(h\)</span> 的相似度；<span class="math inline">\(H\)</span> 表示用户 <span class="math inline">\(u\)</span> 的正反馈物品集合。</p>
<ul>
<li>根据物品向量找到 top k 相似物品</li>
<li>将用户对相似物品的评分加权平均，即得用户对目标物品的评分</li>
</ul>
<h2 data-number="3.3" id="矩阵分解"><span class="header-section-number">3.3</span> 矩阵分解</h2>
<p>分解共现矩阵得到用户和物品的隐向量：</p>
<p><span id="eq:matrix_factorization"><span class="math display">\[\m{R} = \m{U}\m{V}\qquad(6)\]</span></span></p>
<p>其中，<span class="math inline">\(\m{R}\)</span> 为 <span class="math inline">\(m\times n\)</span> 维的共现矩阵，<span class="math inline">\(\m{U}\)</span> 为 <span class="math inline">\(m\times k\)</span> 维的用户矩阵， <span class="math inline">\(\m{V}\)</span> 为 <span class="math inline">\(k\times n\)</span> 维的物品矩阵。</p>
<p><span id="eq:matrix_factorization_r"><span class="math display">\[\hat{r}_{ui} = \T{\v{q}}_i\v{p}_u\qquad(7)\]</span></span></p>
<p>其中，<span class="math inline">\(\v{p}_u\)</span> 表示 <span class="math inline">\(\m{U}\)</span> 的第 <span class="math inline">\(u\)</span> 行组成的向量，<span class="math inline">\(\v{q}_i\)</span> 表示 <span class="math inline">\(\m{V}\)</span> 中的第 <span class="math inline">\(i\)</span> 列组成的向量。</p>
<h3 data-number="3.3.1" id="奇异值分解"><span class="header-section-number">3.3.1</span> 奇异值分解</h3>
<ul>
<li>共现矩阵有大量缺失值，不适于直接 SVD</li>
<li>计算复杂度高</li>
</ul>
<h3 data-number="3.3.2" id="梯度下降"><span class="header-section-number">3.3.2</span> 梯度下降</h3>
<p>损失函数：</p>
<p><span id="eq:matrix_factorization_loss"><span class="math display">\[\min\sum_{(u,i)\in K}(r_{ui} - \T{\v{q}}_i\v{p}_u)^2\qquad(8)\]</span></span></p>
<p>其中，<span class="math inline">\(K\)</span> 是所有用户评分样本的集合。</p>
<h3 data-number="3.3.3" id="消除用户和物品打分的偏差"><span class="header-section-number">3.3.3</span> 消除用户和物品打分的偏差</h3>
<p><span id="eq:matrix_factorization_r_bias"><span class="math display">\[\hat{r}_{ui} = \mu + b_i + b_u + \T{\v{q}}_i\v{p}_u\qquad(9)\]</span></span></p>
<p>其中，<span class="math inline">\(\mu\)</span> 是全局偏差，<span class="math inline">\(b_i\)</span> 是物品偏差，<span class="math inline">\(b_u\)</span> 是用户偏差。</p>
<h2 data-number="3.4" id="逻辑回归"><span class="header-section-number">3.4</span> 逻辑回归</h2>
<h3 data-number="3.4.1" id="输出"><span class="header-section-number">3.4.1</span> 输出</h3>
<p><span id="eq:lr_output"><span class="math display">\[\hat{y} = \sigmoid(\T{\v{x}}\v{w} + b)\qquad(10)\]</span></span></p>
<h3 data-number="3.4.2" id="损失函数"><span class="header-section-number">3.4.2</span> 损失函数</h3>
<p><span id="eq:lr_loss"><span class="math display">\[
\begin{align}
J(\v{w}) &amp;= \frac{1}{m}\sum_{i=1}^m H(p(\v{y}), p(\hat{\v{y}})) \\
&amp;= -\frac{1}{m}\sum_{i=1}^m[y_i\log f_{\v{w}}(\v{x}_i) + (1-y_i)\log (1-f_{\v{w}}(\v{x}_i))]
\end{align}
\qquad(11)\]</span></span></p>
<blockquote>
<p>也可以用极大似然估计解释，<span class="math inline">\(P(y\mid \v{x};\v{w}) = (f_{\v{w}}(\v{x}))^y(1-f_{\v{w}}(\v{x}))^{1-y}\)</span>。</p>
</blockquote>
<h2 data-number="3.5" id="fm---ffm"><span class="header-section-number">3.5</span> FM -&gt; FFM</h2>
<h3 data-number="3.5.1" id="poly2"><span class="header-section-number">3.5.1</span> POLY2</h3>
<p><span id="eq:poly2"><span class="math display">\[\phi\mathrm{POLY2}(\v{w},\v{x}) =
\sum_{j_1=1}^{n-1}\sum_{j_2=j_1+1}^n w_{h(j_1,j_2)}x_{j_1}x_{j_2}\qquad(12)\]</span></span></p>
<h3 data-number="3.5.2" id="fm"><span class="header-section-number">3.5.2</span> FM</h3>
<p><span id="eq:fm"><span class="math display">\[\phi\mathrm{FM}(\v{w},\v{x}) =
\sum_{j_1=1}^{n-1}\sum_{j_2=j_1+1}^n (\v{w}_{j_1}\cdot\v{w}_{j_2})x_{j_1}x_{j_2}\qquad(13)\]</span></span></p>
<h3 data-number="3.5.3" id="ffm"><span class="header-section-number">3.5.3</span> FFM</h3>
<p><span id="eq:ffm"><span class="math display">\[\phi\mathrm{FFM}(\v{w},\v{x}) =
\sum_{j_1=1}^{n-1}\sum_{j_2=j_1+1}^n (\v{w}_{j_1,f_2}\cdot\v{w}_{j_2,f_1})x_{j_1}x_{j_2}\qquad(14)\]</span></span></p>
<h2 data-number="3.6" id="gbdt-lr"><span class="header-section-number">3.6</span> GBDT + LR</h2>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/GBDT&#43;LR_architecture.jpg" id="fig:GBDT_LR_architecture" alt="图 2: GBDT+LR 架构" /><figcaption aria-hidden="true">图 2: GBDT+LR 架构</figcaption>
</figure>
<h2 data-number="3.7" id="ls-plm"><span class="header-section-number">3.7</span> LS-PLM</h2>
<h3 data-number="3.7.1" id="输出-1"><span class="header-section-number">3.7.1</span> 输出</h3>
<p><span id="eq:ls_plm_y"><span class="math display">\[
\begin{align}
f(\v{x}) &amp;= \sum_{i=1}^m \pi_i(\v{x})\cdot\eta_i(\v{x}) \\
&amp;= \sum_{i=1}^m \frac{\e^{\v{\mu_i}\cdot\v{x}}}{\sum_{j=1}^m\e^{\v{\mu_j}\cdot\v{x}}}\cdot\frac{1}{1+\e^{-\v{w_i}\cdot\v{x}}}
\end{align}
\qquad(15)\]</span></span></p>
<p>其中，<span class="math inline">\(m\)</span> 为分片数，<span class="math inline">\(\pi\)</span> 为聚类函数（这里采用 softmax 对样本进行多分类）。</p>
<h2 data-number="3.8" id="autorec"><span class="header-section-number">3.8</span> AutoRec</h2>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/auto_rec_architecture.png" id="fig:auto_rec_architecture" alt="图 3: AutoRec 架构[1]" /><figcaption aria-hidden="true">图 3: AutoRec 架构<span class="citation" data-cites="sedhain2015autorec"><sup>[<a href="#ref-sedhain2015autorec" role="doc-biblioref">1</a>]</sup></span></figcaption>
</figure>
<h3 data-number="3.8.1" id="损失函数-1"><span class="header-section-number">3.8.1</span> 损失函数</h3>
<p><span id="eq:auto_rec_loss"><span class="math display">\[\min_{\theta}\left[\sum_{\v{r}\in S}\lVert\v{r}-h(\v{r};\theta)\rVert_2^2
+ \frac{\lambda}{2}(\lVert\m{W}_F^2\rVert + \lVert\m{V}\rVert_F^2)\right]\qquad(16)\]</span></span></p>
<p>其中，<span class="math inline">\(h(\v{r};\theta)\)</span> 为重建函数；<span class="math inline">\(\v{r}^{(i)}=\T{(R_{1i},\dots,R_{mi})}\)</span> 为物品 <span class="math inline">\(i\)</span> 的评分向量。</p>
<h3 data-number="3.8.2" id="重建函数"><span class="header-section-number">3.8.2</span> 重建函数</h3>
<p><span id="eq:auto_rec_reconstruction"><span class="math display">\[h(\v{r};\theta)=f(\m{W}\cdot g(\m{V}\v{r}+\mu)+b)\qquad(17)\]</span></span></p>
<h3 data-number="3.8.3" id="输出-2"><span class="header-section-number">3.8.3</span> 输出</h3>
<p><span id="eq:auto_rec_output"><span class="math display">\[\hat{R}_{ui} = h(\v{r}^{(i)};\theta)_u\qquad(18)\]</span></span></p>
<h2 data-number="3.9" id="deep-crossing"><span class="header-section-number">3.9</span> Deep Crossing</h2>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/deep_crossing_architecture.png" id="fig:deep_crossing_architecture" alt="图 4: Deep Crossing 架构[2]" /><figcaption aria-hidden="true">图 4: Deep Crossing 架构<span class="citation" data-cites="shan2016deep"><sup>[<a href="#ref-shan2016deep" role="doc-biblioref">2</a>]</sup></span></figcaption>
</figure>
<h3 data-number="3.9.1" id="残差神经网络"><span class="header-section-number">3.9.1</span> 残差神经网络</h3>
<p>好处：</p>
<ul>
<li>减少过拟合</li>
<li>减弱梯度消失现象，加快收敛速度</li>
</ul>
<h2 data-number="3.10" id="neuralcf"><span class="header-section-number">3.10</span> NeuralCF</h2>
<p>用多层神经网络代替矩阵分解的内积操作。</p>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/neural_cf_architecture.png" id="fig:neural_cf_architecture" alt="图 5: NeuralCF 架构[3]" /><figcaption aria-hidden="true">图 5: NeuralCF 架构<span class="citation" data-cites="he2017neural"><sup>[<a href="#ref-he2017neural" role="doc-biblioref">3</a>]</sup></span></figcaption>
</figure>
<h2 data-number="3.11" id="pnn"><span class="header-section-number">3.11</span> PNN</h2>
<p>乘积层代替 Deep Crossing 模型中的 Stacking 层。</p>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/pnn_architecture.png" id="fig:pnn_architecture" alt="图 6: PNN 架构[4]" /><figcaption aria-hidden="true">图 6: PNN 架构<span class="citation" data-cites="qu2016product"><sup>[<a href="#ref-qu2016product" role="doc-biblioref">4</a>]</sup></span></figcaption>
</figure>
<h2 data-number="3.12" id="wide-deep"><span class="header-section-number">3.12</span> Wide &amp; Deep</h2>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/wide_deep_architecture.png" id="fig:wide_deep_architecture" alt="图 7: Wide &amp; Deep 架构[5]" /><figcaption aria-hidden="true">图 7: Wide &amp; Deep 架构<span class="citation" data-cites="cheng2016wide"><sup>[<a href="#ref-cheng2016wide" role="doc-biblioref">5</a>]</sup></span></figcaption>
</figure>
<p>Cross Product Transformation 为：</p>
<p><span class="math display">\[\phi_k(\v{x}) = \prod_{i=1}^d x_i^{c_{ki}}\quad c_{ki}\in\{0,1\}\]</span></p>
<p>其中，<span class="math inline">\(c_{ki}\)</span> 当第 <span class="math inline">\(i\)</span> 个特征属于第 <span class="math inline">\(k\)</span> 个组合特征时为 <span class="math inline">\(1\)</span>，否则为 <span class="math inline">\(0\)</span>；<span class="math inline">\(x_i\)</span> 是第 <span class="math inline">\(i\)</span> 个特征的值。</p>
<h2 data-number="3.13" id="deep-cross"><span class="header-section-number">3.13</span> Deep &amp; Cross</h2>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/deep_cross_architecture.png" id="fig:deep_cross_architecture" style="width:60.0%" alt="图 8: Deep &amp; Cross 架构[6]" /><figcaption aria-hidden="true">图 8: Deep &amp; Cross 架构<span class="citation" data-cites="wang2017deep"><sup>[<a href="#ref-wang2017deep" role="doc-biblioref">6</a>]</sup></span></figcaption>
</figure>
<p>Cross 网络的运算为：</p>
<p><span id="eq:deep_cross_cross"><span class="math display">\[\v{x}_{l+1} = \v{x}_0\T{\v{x}_l}\v{w}_l + \v{b}_l + \v{x}_l\qquad(19)\]</span></span></p>
<h2 data-number="3.14" id="fnn"><span class="header-section-number">3.14</span> FNN</h2>
<p>用 FM 的隐向量初始化 Embedding 层。</p>
<p>为什么 Embedding 层收敛速度较慢？</p>
<ul>
<li>Embedding 参数多</li>
<li>输入向量稀疏</li>
</ul>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/fnn_architecture.png" id="fig:fnn_architecture" alt="图 9: FNN 架构[7]" /><figcaption aria-hidden="true">图 9: FNN 架构<span class="citation" data-cites="zhang2016deep"><sup>[<a href="#ref-zhang2016deep" role="doc-biblioref">7</a>]</sup></span></figcaption>
</figure>
<p>其中，<span class="math inline">\(\v{w}\)</span> 和 <span class="math inline">\(\v{v}\)</span> 对应于 FM 中的参数：</p>
<p><span id="eq:fm_output"><span class="math display">\[\hat{\v{y}} = \sigmoid\left(w_0 + \sum_{i=1}^N w_i x_i +
\sum_{i=1}^N\sum_{j=i+1}^N\langle\v{v}_i,\v{v}_j\rangle x_i x_j\right)
\qquad(20)\]</span></span></p>
<h2 data-number="3.15" id="deepfm"><span class="header-section-number">3.15</span> DeepFM</h2>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/deep_fm_architecture.png" id="fig:deep_fm_architecture" alt="图 10: DeepFM 架构[8]" /><figcaption aria-hidden="true">图 10: DeepFM 架构<span class="citation" data-cites="guo2017deepfm"><sup>[<a href="#ref-guo2017deepfm" role="doc-biblioref">8</a>]</sup></span></figcaption>
</figure>
<h2 data-number="3.16" id="nfm"><span class="header-section-number">3.16</span> NFM</h2>
<p>用神经网络代替 FM 的二阶特征交叉。</p>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/nfm_architecture.png" id="fig:nfm_architecture" alt="图 11: NFM 架构[9]" /><figcaption aria-hidden="true">图 11: NFM 架构<span class="citation" data-cites="he2017nfm"><sup>[<a href="#ref-he2017nfm" role="doc-biblioref">9</a>]</sup></span></figcaption>
</figure>
<p>Bi-Interaction Pooling 具体操作为：</p>
<p><span id="eq:nfm_bi"><span class="math display">\[f_{\mathrm{BI}}(\mathcal{V}_x) = \sum_{i=1}^n\sum_{j=i+1}^n x_i\v{v}_i\odot
x_j\v{v}_j\qquad(21)\]</span></span></p>
<p>其中，<span class="math inline">\(\mathcal{V}_x\)</span> 是 Embedding 集合。</p>
<h2 data-number="3.17" id="afm"><span class="header-section-number">3.17</span> AFM</h2>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/afm_architecture.png" id="fig:afm_architecture" alt="图 12: AFM 架构[10]" /><figcaption aria-hidden="true">图 12: AFM 架构<span class="citation" data-cites="xiao2017attentional"><sup>[<a href="#ref-xiao2017attentional" role="doc-biblioref">10</a>]</sup></span></figcaption>
</figure>
<p>特征交叉采用元素积：</p>
<p><span id="eq:afm_pi"><span class="math display">\[f_{\mathrm{PI}}(\mathcal{E}) = \{(\v{v}_i\odot\v{v}_j) x_i x_j\mid
(i,j)\in\mathcal{R}_x\}\qquad(22)\]</span></span></p>
<p>其中，PI 表示 Pair-wise Interaction Layer；<span class="math inline">\(\mathcal{E} = \{\v{v}_i x_i\mid i\in\mathcal{X}\}\)</span>；<span class="math inline">\(\mathcal{X}\)</span> 为非零特征的索引集合；<span class="math inline">\(\mathcal{R}_x = \{(i,j)\mid i\in\mathcal{X}, j\in\mathcal{X}, j&gt;i\}\)</span>。</p>
<p><span id="eq:afm_att"><span class="math display">\[
\begin{align}
f_{\mathrm{Att}}(f_{\mathrm{PI}}(\mathcal{E})) &amp;= \sum_{(i,j)\in\mathcal{R}_x}
a_{ij}(\v{v}_i\odot\v{v}_j) x_i x_j \\
a_{ij} &amp;= \frac{\exp(a&#39;_{ij})}{\sum_{(i,j)\in\mathcal{R}_x}\exp(a&#39;_{ij})} \\
a&#39;_{ij} &amp;= \T{\v{h}}\ReLU(\m{W}(\v{v}_i\odot\v{v}_j)x_i x_j +\v{b})
\end{align}
\qquad(23)\]</span></span></p>
<h2 data-number="3.18" id="din"><span class="header-section-number">3.18</span> DIN</h2>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/din_architecture.png" id="fig:din_architecture" alt="图 13: DIN 架构[11]" /><figcaption aria-hidden="true">图 13: DIN 架构<span class="citation" data-cites="zhou2018deep"><sup>[<a href="#ref-zhou2018deep" role="doc-biblioref">11</a>]</sup></span></figcaption>
</figure>
<h3 data-number="3.18.1" id="注意力"><span class="header-section-number">3.18.1</span> 注意力</h3>
<p><span id="eq:din_attention"><span class="math display">\[\v{v}_U(A) = f(\v{v}_A,\v{e}_1,\v{e}_2,\dots,\v{e}_H)
= \sum_{j=1}^H a(\v{e}_j,\v{v}_A)\v{e}_j
= \sum_{j=1}^H w_j\v{e}_j\qquad(24)\]</span></span></p>
<p>其中，<span class="math inline">\(\{\v{e}_1,\v{e}_2,\dots,\v{e}_H\}\)</span> 是用户 U 的历史行为的 Embedding 向量； <span class="math inline">\(\v{v}_A\)</span> 是广告 A 的 Embedding 向量。</p>
<h2 data-number="3.19" id="dien"><span class="header-section-number">3.19</span> DIEN</h2>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/dien_architecture.png" id="fig:dien_architecture" alt="图 14: DIEN 架构[12]" /><figcaption aria-hidden="true">图 14: DIEN 架构<span class="citation" data-cites="zhou2019deep"><sup>[<a href="#ref-zhou2019deep" role="doc-biblioref">12</a>]</sup></span></figcaption>
</figure>
<h3 data-number="3.19.1" id="augru"><span class="header-section-number">3.19.1</span> AUGRU</h3>
<p>AUGRU 改变了更新门：</p>
<p><span id="eq:dien_update_gate"><span class="math display">\[\tilde{\v{u}}&#39;_t = a_t\v{u}&#39;_t\qquad(25)\]</span></span></p>
<h2 data-number="3.20" id="drn"><span class="header-section-number">3.20</span> DRN</h2>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/drn_deep_reinforcement_recommendation_system.png" id="fig:drn_deep_reinforcement_recommendation_system" alt="图 15: 深度强化学习推荐系统[13]" /><figcaption aria-hidden="true">图 15: 深度强化学习推荐系统<span class="citation" data-cites="zheng2018drn"><sup>[<a href="#ref-zheng2018drn" role="doc-biblioref">13</a>]</sup></span></figcaption>
</figure>
<ul>
<li>State representation 为用户特征，Action representation 为候选新闻特征</li>
<li>用户向 Agent 请求新闻列表，Agent 根据 State representation 和 Action representation 选择最好的 Action 返回给用户，并获取用户反馈</li>
<li>Action 和反馈日志会存入 Agent 的内存，Agent 每小时会利用内存中的日志更新推荐算法</li>
</ul>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/drn_q.png" id="fig:drn_q" style="width:60.0%" alt="图 16: DRN Q 网络[13]" /><figcaption aria-hidden="true">图 16: DRN Q 网络<span class="citation" data-cites="zheng2018drn"><sup>[<a href="#ref-zheng2018drn" role="doc-biblioref">13</a>]</sup></span></figcaption>
</figure>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/drn_model_framework.png" id="fig:drn_model_framework" alt="图 17: DRN 模型框架[13]" /><figcaption aria-hidden="true">图 17: DRN 模型框架<span class="citation" data-cites="zheng2018drn"><sup>[<a href="#ref-zheng2018drn" role="doc-biblioref">13</a>]</sup></span></figcaption>
</figure>
<h3 data-number="3.20.1" id="竞争梯度下降法"><span class="header-section-number">3.20.1</span> 竞争梯度下降法</h3>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/drn_dueling_bandit_gradient_descent.png" id="fig:drn_dueling_bandit_gradient_descent" style="width:60.0%" alt="图 18: 竞争梯度下降法[13]" /><figcaption aria-hidden="true">图 18: 竞争梯度下降法<span class="citation" data-cites="zheng2018drn"><sup>[<a href="#ref-zheng2018drn" role="doc-biblioref">13</a>]</sup></span></figcaption>
</figure>
<p><span id="eq:drn_delta_w"><span class="math display">\[\Delta\m{W} = \alpha\cdot\rand(-1,1)\cdot\m{W}\qquad(26)\]</span></span></p>
<p>其中，<span class="math inline">\(\alpha\)</span> 是探索因子。</p>
<h1 data-number="4" id="embedding"><span class="header-section-number">4</span> Embedding</h1>
<h2 data-number="4.1" id="不同-embedding-的优缺点"><span class="header-section-number">4.1</span> 不同 Embedding 的优缺点</h2>
<div id="tbl:embedding_pros_cons">
<table>
<caption>表 3: 不同 Embedding 的优缺点</caption>
<thead>
<tr class="header">
<th>Embedding</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Word2vec</td>
<td>奠基</td>
<td></td>
</tr>
<tr class="even">
<td>Item2vec</td>
<td>没有时间窗口</td>
<td>只有序列型结构</td>
</tr>
<tr class="odd">
<td>EGES</td>
<td>缓解冷启动</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<h2 data-number="4.2" id="word2vec"><span class="header-section-number">4.2</span> Word2vec</h2>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/word2vec_architecture.png" id="fig:word2vec_architecture" style="width:80.0%" alt="图 19: CBOW 与 Skip-gram 架构[14]" /><figcaption aria-hidden="true">图 19: CBOW 与 Skip-gram 架构<span class="citation" data-cites="mikolov2013efficient"><sup>[<a href="#ref-mikolov2013efficient" role="doc-biblioref">14</a>]</sup></span></figcaption>
</figure>
<ul>
<li>根据经验，Skip-gram 的效果更好</li>
</ul>
<h3 data-number="4.2.1" id="基本结构"><span class="header-section-number">4.2.1</span> 基本结构</h3>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/word2vec_base_net.png" id="fig:word2vec_base_net" style="width:60.0%" alt="图 20: word2vec 基本网络结构[15]" /><figcaption aria-hidden="true">图 20: word2vec 基本网络结构<span class="citation" data-cites="rong2014word2vec"><sup>[<a href="#ref-rong2014word2vec" role="doc-biblioref">15</a>]</sup></span></figcaption>
</figure>
<h4 data-number="4.2.1.1" id="输出-3"><span class="header-section-number">4.2.1.1</span> 输出</h4>
<p><span id="eq:word2vec_base_output"><span class="math display">\[y_j = p(w_j\mid w_I)
= \frac{\exp(\T{\v{v}&#39;_{w_j}}\v{v}_{w_I})}{\sum_{j&#39;=1}^V\exp(\T{\v{v}&#39;_{w_{j&#39;}}}\v{v}_{w_I})}
\qquad(27)\]</span></span></p>
<p>其中，<span class="math inline">\(\v{v}_{w_I}\in\R^{N\times 1}\)</span> 为 <span class="math inline">\(\m{W}\)</span> 的第 <span class="math inline">\(I\)</span> 行； <span class="math inline">\(\v{v}&#39;_{w_j}\in\R^{N\times 1}\)</span> 为 <span class="math inline">\(\m{W}&#39;\)</span> 的第 <span class="math inline">\(j\)</span> 列。<span class="math inline">\(\m{W}\)</span> 为词向量矩阵。</p>
<h4 data-number="4.2.1.2" id="损失函数-2"><span class="header-section-number">4.2.1.2</span> 损失函数</h4>
<p><span id="eq:word2vec_base_loss"><span class="math display">\[L = -\log p(w_O\mid w_I)\qquad(28)\]</span></span></p>
<p>其中，<span class="math inline">\(O\)</span> 为输出单词的索引；这个损失可以看做最大似然概率，也可以看做交叉熵。</p>
<h4 data-number="4.2.1.3" id="负采样"><span class="header-section-number">4.2.1.3</span> 负采样</h4>
<p><span id="eq:word2vec_negative_sample"><span class="math display">\[L = -\log \sigma(\T{\v{v}&#39;_{w_O}}\v{h})
- \sum_{w_j\in\mathcal{W}_{\mathrm{neg}}}\log\sigma(-\T{\v{v}&#39;_{w_j}}\v{h})
\qquad(29)\]</span></span></p>
<p>其中，<span class="math inline">\(w_O\)</span> 是输出单词；<span class="math inline">\(\mathcal{W}_{\mathrm{neg}} = \{w_j\mid j=1,\cdots,K\}\)</span> 是采样得到的负样本集合。</p>
<h2 data-number="4.3" id="item2vec"><span class="header-section-number">4.3</span> Item2vec</h2>
<h2 data-number="4.4" id="deepwalk"><span class="header-section-number">4.4</span> DeepWalk</h2>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/deep_walk_architecture.png" id="fig:deep_walk_architecture" alt="图 21: DeepWalk 架构[16]" /><figcaption aria-hidden="true">图 21: DeepWalk 架构<span class="citation" data-cites="wang2018billion"><sup>[<a href="#ref-wang2018billion" role="doc-biblioref">16</a>]</sup></span></figcaption>
</figure>
<h3 data-number="4.4.1" id="随机游走的转移概率wang2018billion"><span class="header-section-number">4.4.1</span> 随机游走的转移概率<span class="citation" data-cites="wang2018billion"><sup>[<a href="#ref-wang2018billion" role="doc-biblioref">16</a>]</sup></span></h3>
<p><span class="math display">\[
P(v_j\mid v_i) =
\begin{cases}
\frac{M_{ij}}{\sum_{j&#39;\in N_+(v_i)}M_{ij&#39;}}, &amp;\mathrm{if}\;v_j\in N_+(v_i)\\
0, &amp;\mathrm{if}\;e_{ij}\notin\mathcal{E}
\end{cases}
\]</span></p>
<p>其中，<span class="math inline">\(N_+(v_i)\)</span> 表示 <span class="math inline">\(v_i\)</span> 的出边集合；<span class="math inline">\(M_{ij}\)</span> 表示节点 <span class="math inline">\(i\)</span> 到节点 <span class="math inline">\(j\)</span> 边的权重；<span class="math inline">\(\mathcal{E}\)</span> 表示所有边的集合。</p>
<h2 data-number="4.5" id="node2vec"><span class="header-section-number">4.5</span> node2vec</h2>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/node2vec_bfs_dfs.png" id="fig:node2vec_bfs_dfs" style="width:60.0%" alt="图 22: node2vec 广度优先搜索与深度优先搜索[17]" /><figcaption aria-hidden="true">图 22: node2vec 广度优先搜索与深度优先搜索<span class="citation" data-cites="grover2016node2vec"><sup>[<a href="#ref-grover2016node2vec" role="doc-biblioref">17</a>]</sup></span></figcaption>
</figure>
<ul>
<li>同质性：图. 22 中的 <span class="math inline">\(u\)</span> 与 <span class="math inline">\(s_1\)</span> 属于同一社区，Embedding 应该相似</li>
<li>同构性：图. 22 中的 <span class="math inline">\(u\)</span> 与 <span class="math inline">\(s_6\)</span> 扮演相似的结构角色， Embedding 应该相似</li>
<li>BFS 能发现同构性；DFS 能发现同质性</li>
</ul>
<h3 data-number="4.5.1" id="跳转概率"><span class="header-section-number">4.5.1</span> 跳转概率</h3>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/node2vec_transition.png" id="fig:node2vec_transition" style="width:60.0%" alt="图 23: node2vec 跳转概率[17]" /><figcaption aria-hidden="true">图 23: node2vec 跳转概率<span class="citation" data-cites="grover2016node2vec"><sup>[<a href="#ref-grover2016node2vec" role="doc-biblioref">17</a>]</sup></span></figcaption>
</figure>
<p>未归一化的跳转概率为：</p>
<p><span id="eq:node2vec_transition"><span class="math display">\[\pi_{vx} = \alpha_{pq}(t,x)\cdot w_{vx}\qquad(30)\]</span></span></p>
<p>其中，</p>
<p><span id="eq:node2vec_alpha"><span class="math display">\[
\alpha_{pq}(t,x) =
\begin{cases}
\frac{1}{p}\quad &amp;\mathrm{if}\;d_{tx} = 0\\
1 &amp;\mathrm{if}\;d_{tx} = 1\\
\frac{1}{q}\quad &amp;\mathrm{if}\;d_{tx} = 2
\end{cases}
\qquad(31)\]</span></span></p>
<p><span class="math inline">\(t\)</span> 为上一个节点；<span class="math inline">\(w_{vx}\)</span> 是边 <span class="math inline">\(vx\)</span> 的权重；<span class="math inline">\(d_{tx}\)</span> 表示节点 <span class="math inline">\(t\)</span> 与节点 <span class="math inline">\(x\)</span> 的最短距离；<span class="math inline">\(p\)</span> 为返回参数；<span class="math inline">\(q\)</span> 为进出参数。</p>
<h2 data-number="4.6" id="eges"><span class="header-section-number">4.6</span> EGES</h2>
<figure>
<img src="https://kaizhang16.github.io/note/fig/AI/推荐系统/eges_architecture.png" id="fig:eges_architecture" style="width:60.0%" alt="图 24: EGES 架构[16]" /><figcaption aria-hidden="true">图 24: EGES 架构<span class="citation" data-cites="wang2018billion"><sup>[<a href="#ref-wang2018billion" role="doc-biblioref">16</a>]</sup></span></figcaption>
</figure>
<h3 data-number="4.6.1" id="隐层向量"><span class="header-section-number">4.6.1</span> 隐层向量</h3>
<p><span class="math display">\[\m{H}_v = \frac{\sum_{j=0}^n \e^{a_v^j}\m{W}_v^j}{\sum_{j=0}^n \e^{a_v^j}}\]</span></p>
<p>使用 <span class="math inline">\(e^{a_v^j}\)</span> 作为权重是想让权重总是大于 <span class="math inline">\(0\)</span>。</p>
<h2 data-number="4.7" id="局部敏感哈希"><span class="header-section-number">4.7</span> 局部敏感哈希</h2>
<p>欧式空间中，将高维空间的点映射到低维空间：</p>
<ul>
<li>原本相近的点在低维空间肯定依然相近</li>
<li>原本远离的点则有一定概率变成相近的点</li>
</ul>
<p><span id="eq:lsh_hash"><span class="math display">\[h^{\v{x},b} = \left\lfloor\frac{\v{v}\cdot\v{x} + b}{w}\right\rfloor\qquad(32)\]</span></span></p>
<h1 data-number="5" id="特征工程"><span class="header-section-number">5</span> 特征工程</h1>
<h2 data-number="5.1" id="原则"><span class="header-section-number">5.1</span> 原则</h2>
<ul>
<li>尽可能暴露有用信息</li>
<li>尽量摈弃冗余信息</li>
</ul>
<h1 data-number="6" id="召回策略"><span class="header-section-number">6</span> 召回策略</h1>
<div id="tbl:recall_sort">
<table>
<caption>表 4: 召回层与排序层</caption>
<thead>
<tr class="header">
<th>层</th>
<th>目标</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>召回层</td>
<td>尽量让用户感兴趣的物品被快速召回</td>
<td>候选集合大、速度快、模型简单、特征较少</td>
</tr>
<tr class="even">
<td>排序层</td>
<td>得到精准的排序结果</td>
<td>候选集合小、模型复杂、特征较多</td>
</tr>
</tbody>
</table>
</div>
<h1 data-number="7" id="冷启动的解决办法"><span class="header-section-number">7</span> 冷启动的解决办法</h1>
<h2 data-number="7.1" id="基于规则的冷启动"><span class="header-section-number">7.1</span> 基于规则的冷启动</h2>
<h2 data-number="7.2" id="丰富冷启动过程中可获得的用户和物品特征"><span class="header-section-number">7.2</span> 丰富冷启动过程中可获得的用户和物品特征</h2>
<ul>
<li>用户的注册信息</li>
<li>第三方 DMP 提供的用户信息</li>
<li>物品的内容特征</li>
<li>引导用户输入的冷启动特征</li>
</ul>
<h2 data-number="7.3" id="利用主动学习迁移学习和探索与利用机制"><span class="header-section-number">7.3</span> 利用主动学习、迁移学习和“探索与利用”机制</h2>
<h3 data-number="7.3.1" id="探索与利用机制"><span class="header-section-number">7.3.1</span> “探索与利用”机制</h3>
<p>UCB (Upper Confidence Bound，置信区间上界)：</p>
<p><span id="eq:ucb"><span class="math display">\[\mathrm{UCB}(j) = \mean{x_j}+\sqrt{\frac{2\ln n}{n_j}}\qquad(33)\]</span></span></p>
<p>其中，<span class="math inline">\(\mean{x_j}\)</span> 为第 <span class="math inline">\(j\)</span> 个物品的平均回报；<span class="math inline">\(n_j\)</span> 为第 <span class="math inline">\(j\)</span> 个物品的曝光次数； <span class="math inline">\(n\)</span> 为所有物品的曝光次数。可以看到，UCB 倾向于推荐冷启动的物品。</p>
<h1 data-number="8" id="推荐模型离线训练"><span class="header-section-number">8</span> 推荐模型离线训练</h1>
<h2 data-number="8.1" id="spark-mlib"><span class="header-section-number">8.1</span> Spark MLib</h2>
<h2 data-number="8.2" id="parameter-server"><span class="header-section-number">8.2</span> Parameter Server</h2>
<ul>
<li>分布式梯度下降策略：同步阻断 -&gt; 异步非阻断</li>
<li>多 server</li>
<li>使用一致性哈希、参数范围拉取、参数范围推送，减小带宽</li>
</ul>
<h1 data-number="9" id="推荐系统的评估"><span class="header-section-number">9</span> 推荐系统的评估</h1>
<h2 data-number="9.1" id="holdout-检验"><span class="header-section-number">9.1</span> Holdout 检验</h2>
<h2 data-number="9.2" id="k-fold-交叉验证"><span class="header-section-number">9.2</span> K-fold 交叉验证</h2>
<p>把 K 次评估指标的平均值作为最终的评估指标。</p>
<h1 class="unnumbered" id="参考文献">参考文献</h1>
<div id="refs" class="references csl-bib-body" role="doc-bibliography">
<div id="ref-sedhain2015autorec" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">SEDHAIN S, MENON A K, SANNER S, 等. Autorec: Autoencoders meet collaborative filtering[C]//Proceedings of the 24th international conference on World Wide Web.</div>
</div>
<div id="ref-shan2016deep" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">SHAN Y, HOENS T R, JIAO J, 等. Deep crossing: Web-scale modeling without manually crafted combinatorial features[C]//Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining.</div>
</div>
<div id="ref-he2017neural" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">HE X, LIAO L, ZHANG H, 等. Neural collaborative filtering[C]//Proceedings of the 26th international conference on world wide web.</div>
</div>
<div id="ref-qu2016product" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">QU Y, CAI H, REN K, 等. Product-based neural networks for user response prediction[C]//2016 IEEE 16th International Conference on Data Mining (ICDM). IEEE, 2016: 1149–1154.</div>
</div>
<div id="ref-cheng2016wide" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">CHENG H-T, KOC L, HARMSEN J, 等. Wide &amp; deep learning for recommender systems[C]//Proceedings of the 1st workshop on deep learning for recommender systems.</div>
</div>
<div id="ref-wang2017deep" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">WANG R, FU B, FU G, 等. Deep &amp; cross network for ad click predictions[M]//Proceedings of the ADKDD’17.</div>
</div>
<div id="ref-zhang2016deep" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">ZHANG W, DU T, WANG J. Deep learning over multi-field categorical data[C]//European conference on information retrieval. Springer, 2016: 45–57.</div>
</div>
<div id="ref-guo2017deepfm" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">GUO H, TANG R, YE Y, 等. DeepFM: a factorization-machine based neural network for CTR prediction[J]. arXiv preprint arXiv:1703.04247, 2017.</div>
</div>
<div id="ref-he2017nfm" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">HE X, CHUA T-S. Neural factorization machines for sparse predictive analytics[C]//Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval.</div>
</div>
<div id="ref-xiao2017attentional" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">XIAO J, YE H, HE X, 等. Attentional factorization machines: Learning the weight of feature interactions via attention networks[J]. arXiv preprint arXiv:1708.04617, 2017.</div>
</div>
<div id="ref-zhou2018deep" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">ZHOU G, ZHU X, SONG C, 等. Deep interest network for click-through rate prediction[C]//Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining.</div>
</div>
<div id="ref-zhou2019deep" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[12] </div><div class="csl-right-inline">ZHOU G, MOU N, FAN Y, 等. Deep interest evolution network for click-through rate prediction[C]//Proceedings of the AAAI conference on artificial intelligence.</div>
</div>
<div id="ref-zheng2018drn" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[13] </div><div class="csl-right-inline">ZHENG G, ZHANG F, ZHENG Z, 等. DRN: A deep reinforcement learning framework for news recommendation[C]//Proceedings of the 2018 World Wide Web Conference.</div>
</div>
<div id="ref-mikolov2013efficient" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[14] </div><div class="csl-right-inline">MIKOLOV T, CHEN K, CORRADO G, 等. Efficient estimation of word representations in vector space[J]. arXiv preprint arXiv:1301.3781, 2013.</div>
</div>
<div id="ref-rong2014word2vec" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[15] </div><div class="csl-right-inline">RONG X. word2vec parameter learning explained[J]. arXiv preprint arXiv:1411.2738, 2014.</div>
</div>
<div id="ref-wang2018billion" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[16] </div><div class="csl-right-inline">WANG J, HUANG P, ZHAO H, 等. Billion-scale commodity embedding for e-commerce recommendation in alibaba[C]//Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining.</div>
</div>
<div id="ref-grover2016node2vec" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[17] </div><div class="csl-right-inline">GROVER A, LESKOVEC J. node2vec: Scalable feature learning for networks[C]//Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining.</div>
</div>
</div>

<nav id="TableOfContents" role="doc-toc">
  <h2 id="toc-title">目录</h2>
  <ul>
  <li><a href="#术语"><span class="toc-section-number">1</span> 术语</a></li>
  <li><a href="#架构"><span class="toc-section-number">2</span> 架构</a></li>
  <li><a href="#算法"><span class="toc-section-number">3</span> 算法</a>
  <ul>
  <li><a href="#不同算法的优缺点"><span class="toc-section-number">3.1</span> 不同算法的优缺点</a></li>
  <li><a href="#协同过滤"><span class="toc-section-number">3.2</span> 协同过滤</a>
  <ul>
  <li><a href="#共现矩阵"><span class="toc-section-number">3.2.1</span> 共现矩阵</a></li>
  <li><a href="#相似度"><span class="toc-section-number">3.2.2</span> 相似度</a></li>
  <li><a href="#usercf"><span class="toc-section-number">3.2.3</span> UserCF</a></li>
  <li><a href="#itemcf"><span class="toc-section-number">3.2.4</span> ItemCF</a></li>
  </ul></li>
  <li><a href="#矩阵分解"><span class="toc-section-number">3.3</span> 矩阵分解</a>
  <ul>
  <li><a href="#奇异值分解"><span class="toc-section-number">3.3.1</span> 奇异值分解</a></li>
  <li><a href="#梯度下降"><span class="toc-section-number">3.3.2</span> 梯度下降</a></li>
  <li><a href="#消除用户和物品打分的偏差"><span class="toc-section-number">3.3.3</span> 消除用户和物品打分的偏差</a></li>
  </ul></li>
  <li><a href="#逻辑回归"><span class="toc-section-number">3.4</span> 逻辑回归</a>
  <ul>
  <li><a href="#输出"><span class="toc-section-number">3.4.1</span> 输出</a></li>
  <li><a href="#损失函数"><span class="toc-section-number">3.4.2</span> 损失函数</a></li>
  </ul></li>
  <li><a href="#fm---ffm"><span class="toc-section-number">3.5</span> FM -&gt; FFM</a>
  <ul>
  <li><a href="#poly2"><span class="toc-section-number">3.5.1</span> POLY2</a></li>
  <li><a href="#fm"><span class="toc-section-number">3.5.2</span> FM</a></li>
  <li><a href="#ffm"><span class="toc-section-number">3.5.3</span> FFM</a></li>
  </ul></li>
  <li><a href="#gbdt-lr"><span class="toc-section-number">3.6</span> GBDT + LR</a></li>
  <li><a href="#ls-plm"><span class="toc-section-number">3.7</span> LS-PLM</a>
  <ul>
  <li><a href="#输出-1"><span class="toc-section-number">3.7.1</span> 输出</a></li>
  </ul></li>
  <li><a href="#autorec"><span class="toc-section-number">3.8</span> AutoRec</a>
  <ul>
  <li><a href="#损失函数-1"><span class="toc-section-number">3.8.1</span> 损失函数</a></li>
  <li><a href="#重建函数"><span class="toc-section-number">3.8.2</span> 重建函数</a></li>
  <li><a href="#输出-2"><span class="toc-section-number">3.8.3</span> 输出</a></li>
  </ul></li>
  <li><a href="#deep-crossing"><span class="toc-section-number">3.9</span> Deep Crossing</a>
  <ul>
  <li><a href="#残差神经网络"><span class="toc-section-number">3.9.1</span> 残差神经网络</a></li>
  </ul></li>
  <li><a href="#neuralcf"><span class="toc-section-number">3.10</span> NeuralCF</a></li>
  <li><a href="#pnn"><span class="toc-section-number">3.11</span> PNN</a></li>
  <li><a href="#wide-deep"><span class="toc-section-number">3.12</span> Wide &amp; Deep</a></li>
  <li><a href="#deep-cross"><span class="toc-section-number">3.13</span> Deep &amp; Cross</a></li>
  <li><a href="#fnn"><span class="toc-section-number">3.14</span> FNN</a></li>
  <li><a href="#deepfm"><span class="toc-section-number">3.15</span> DeepFM</a></li>
  <li><a href="#nfm"><span class="toc-section-number">3.16</span> NFM</a></li>
  <li><a href="#afm"><span class="toc-section-number">3.17</span> AFM</a></li>
  <li><a href="#din"><span class="toc-section-number">3.18</span> DIN</a>
  <ul>
  <li><a href="#注意力"><span class="toc-section-number">3.18.1</span> 注意力</a></li>
  </ul></li>
  <li><a href="#dien"><span class="toc-section-number">3.19</span> DIEN</a>
  <ul>
  <li><a href="#augru"><span class="toc-section-number">3.19.1</span> AUGRU</a></li>
  </ul></li>
  <li><a href="#drn"><span class="toc-section-number">3.20</span> DRN</a>
  <ul>
  <li><a href="#竞争梯度下降法"><span class="toc-section-number">3.20.1</span> 竞争梯度下降法</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#embedding"><span class="toc-section-number">4</span> Embedding</a>
  <ul>
  <li><a href="#不同-embedding-的优缺点"><span class="toc-section-number">4.1</span> 不同 Embedding 的优缺点</a></li>
  <li><a href="#word2vec"><span class="toc-section-number">4.2</span> Word2vec</a>
  <ul>
  <li><a href="#基本结构"><span class="toc-section-number">4.2.1</span> 基本结构</a></li>
  </ul></li>
  <li><a href="#item2vec"><span class="toc-section-number">4.3</span> Item2vec</a></li>
  <li><a href="#deepwalk"><span class="toc-section-number">4.4</span> DeepWalk</a>
  <ul>
  <li><a href="#随机游走的转移概率wang2018billion"><span class="toc-section-number">4.4.1</span> 随机游走的转移概率<span class="citation" data-cites="wang2018billion"><sup>[<span>16</span>]</sup></span></a></li>
  </ul></li>
  <li><a href="#node2vec"><span class="toc-section-number">4.5</span> node2vec</a>
  <ul>
  <li><a href="#跳转概率"><span class="toc-section-number">4.5.1</span> 跳转概率</a></li>
  </ul></li>
  <li><a href="#eges"><span class="toc-section-number">4.6</span> EGES</a>
  <ul>
  <li><a href="#隐层向量"><span class="toc-section-number">4.6.1</span> 隐层向量</a></li>
  </ul></li>
  <li><a href="#局部敏感哈希"><span class="toc-section-number">4.7</span> 局部敏感哈希</a></li>
  </ul></li>
  <li><a href="#特征工程"><span class="toc-section-number">5</span> 特征工程</a>
  <ul>
  <li><a href="#原则"><span class="toc-section-number">5.1</span> 原则</a></li>
  </ul></li>
  <li><a href="#召回策略"><span class="toc-section-number">6</span> 召回策略</a></li>
  <li><a href="#冷启动的解决办法"><span class="toc-section-number">7</span> 冷启动的解决办法</a>
  <ul>
  <li><a href="#基于规则的冷启动"><span class="toc-section-number">7.1</span> 基于规则的冷启动</a></li>
  <li><a href="#丰富冷启动过程中可获得的用户和物品特征"><span class="toc-section-number">7.2</span> 丰富冷启动过程中可获得的用户和物品特征</a></li>
  <li><a href="#利用主动学习迁移学习和探索与利用机制"><span class="toc-section-number">7.3</span> 利用主动学习、迁移学习和“探索与利用”机制</a>
  <ul>
  <li><a href="#探索与利用机制"><span class="toc-section-number">7.3.1</span> “探索与利用”机制</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#推荐模型离线训练"><span class="toc-section-number">8</span> 推荐模型离线训练</a>
  <ul>
  <li><a href="#spark-mlib"><span class="toc-section-number">8.1</span> Spark MLib</a></li>
  <li><a href="#parameter-server"><span class="toc-section-number">8.2</span> Parameter Server</a></li>
  </ul></li>
  <li><a href="#推荐系统的评估"><span class="toc-section-number">9</span> 推荐系统的评估</a>
  <ul>
  <li><a href="#holdout-检验"><span class="toc-section-number">9.1</span> Holdout 检验</a></li>
  <li><a href="#k-fold-交叉验证"><span class="toc-section-number">9.2</span> K-fold 交叉验证</a></li>
  </ul></li>
  <li><a href="#参考文献">参考文献</a></li>
  </ul>
</nav>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function a(c){const a=window.getSelection(),b=document.createRange();b.selectNodeContents(c),a.removeAllRanges(),a.addRange(b)}document.querySelectorAll("pre code").forEach(b=>{b.addEventListener("click",function(c){a(b.parentElement),navigator.clipboard&&navigator.clipboard.writeText(b.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  



 
      </div>
    </aside>
    
  </main>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>

<script>
  
  const tableOfContents = document.getElementById("TableOfContents");
  const tableOfContents1 = tableOfContents.cloneNode(true);
  document.querySelector(".book-toc-content").appendChild(tableOfContents);
  document.querySelector(".book-header > aside").appendChild(tableOfContents1);

  
  const searchResults = document.getElementById("book-search-results");
  document
    .getElementById("book-search-input")
    .addEventListener("keyup", (event) => {
      
      
      if (event.keyCode === 13) {
        event.preventDefault();
        if (searchResults.childNodes.length > 0) {
          const searchResult = searchResults.childNodes[0].childNodes[0];
          window.location.href = searchResult.href;
        }
      }
    });

  
  MathJax = {
    tex: {
      macros: {
        argmin: ["\\mathop{\\arg\\,\\min}"],
        AveP: ["\\mathrm{AveP}"],
        bm: ["{\\boldsymbol{#1}}", 1],
        cos: ["\\mathrm{cos}"],
        d: ["\\mathrm{d}"],
        data: ["\\mathrm{data}"],
        diag: ["\\mathrm{diag}"],
        e: ["\\mathrm{e}"],
        FN: ["\\mathrm{FN}"],
        FP: ["\\mathrm{FP}"],
        FPR: ["\\mathrm{FPR}"],
        log: ["\\mathrm{log}\\,"],
        MAP: ["\\mathrm{MAP}"],
        m: ["{\\bm{\\mathrm{#1}}}", 1],
        mean: ["{\\overline{#1}}", 1],
        median: ["\\mathrm{median}"],
        model: ["\\mathrm{model}"],
        R: ["\\mathbb{R}"],
        rand: ["\\mathrm{rand}"],
        rel: ["\\mathrm{rel}"],
        ReLU: ["\\mathrm{ReLU}"],
        set: ["{\\mathbb{#1}}", 1],
        sigmoid: ["\\mathrm{sigmoid}"],
        sign: ["\\mathrm{sign}"],
        SNR: ["\\mathrm{SNR}"],
        SO: ["\\mathrm{SO}"],
        tanh: ["\\mathrm{tanh}"],
        TN: ["\\mathrm{TN}"],
        TP: ["\\mathrm{TP}"],
        TPR: ["\\mathrm{TPR}"],
        transformation: ["{\\mathcal{#1}}", 1],
        T: ["{#1}^{\\mathsf{T}}", 1],
        v: ["{\\bm{\\mathrm{#1}}}", 1],
      },
    },
  };

  
  hljs.initHighlightingOnLoad();
  

</script>


<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
></script>




</body>
</html>












