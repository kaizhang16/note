---
title: "机器学习"
---

# 中位数

# 评估指标

|               | 实际 Positive                         | 实际 Negative                        |
|---------------|---------------------------------------|--------------------------------------|
| 预测 Positive | True Positive                         | False Positive（误报，Type I Error） |
| 预测 Negative | False Negative（漏报，Type II Error） | True Negative                        |

: 混淆矩阵 {#tbl:confusion_matrix}

## 精确率（Precision）

你认为的正样本，有多少猜对了（猜的精确性如何）[@ml_precision_recall]：

$$ P = \frac{\TP}{\TP + \FP}$$ {#eq:precision}

在信息检索领域这样定义[@ml_evaluation_measures]：

$$ P = \frac{\vert\{\textrm{relevant documents}\}\cap\{\textrm{retrieved documents}\}\vert}{\vert\{\textrm{retrieved documents}\}\vert}$$ {#eq:precision_information_retrieval}

### P@n

只考虑 top n 个查询结果。[@ml_evaluation_measures]

### AveP(Average Precision)[@ml_evaluation_measures]

$$\AveP = \int_0^1 p(r)\d r$$ {#eq:AveP}
$$\AveP = \sum_{k=1}^n P(k)\Delta r(k)$$ {#eq:AveP_sum}
$$\AveP = \frac{\sum_{k=1}^n P(k)\times \rel(k)}{\vert\{\textrm{relevant documents}\}\vert}$$ {#eq:AveP_k}

其中，

- $k$ 表示在检索文档序列里的排名
- $n$ 表示检索文档的总数，$P(k)$ 表示 top k 的精确率
- $\Delta r(k)$ 表示从项 $k-1$ 到 $k$ 的召回率变化
- $\rel(k)$ 是指示函数，项 $k$ 是相关文档时为 $1$，项 $k$ 不是相关文档时为 $0$

### MAP(Mean Average Precision)

$$\MAP = \frac{\sum_{q=1}^Q \AveP(q)}{Q}$$ {#eq:map}

其中 $Q$ 表示查询总数。

## 召回率（Recall）

正样本有多少被找出来了（召回了多少）[@ml_precision_recall]：

$$R = \frac{\TP}{\TP + \FN}$$ {#eq:recall}

## 准确率（Accuracy）

预测正确的结果占总样本的比例[@ml_accuracy]：

$$A = \frac{\TP+\TN}{\TP+\TN+\FP+\FN}$$ {#eq:accuracy}

## $F_1$

Precision 与 Recall 的调和均值：

$$\frac{2}{F_1} = \frac{1}{P} + \frac{1}{R}$$ {#eq:f1}

## 真阳性率（TPR）[@ml_tpr_fpr]

在所有实际为阳性的样本中，被正确地判断为阳性之比率：

$$ \TPR = \frac{\TP}{\TP + \FN}$$ {#eq:tpr}

与召回率定义相同。

## 伪阳性率（FPR）[@ml_tpr_fpr]

在所有实际为阴性的样本中，被错误地判断为阳性之比率：

$$ \FPR = \frac{\FP}{\FP + \TN}$$ {#eq:fpr}

## ROC 与 Precision-Recall 曲线[@ml_roc]

![一个 ROC 与 Precision-Recall 曲线例子]({{< static_ref "fig/ai/machine_learning/roc_pr.png" >}}){#fig:roc_pr width=80%}

![ROC 与 Precision-Recall 曲线随阈值的动态变化]({{< static_ref "fig/ai/machine_learning/roc_pr.gif" >}}){#fig:roc_pr_dynamic width=80%}

### ROC 与 P-R 曲线的比较[@ml_roc]

![样本不平衡时，ROC 与 Precision-Recall 曲线的比较]({{< static_ref "fig/ai/machine_learning/roc_pr_imbalance.png" >}}){#fig:roc_pr_imbalance width=80%}

- 当正负样本不平衡时，P-R 曲线对误报更敏感

### AUC(Area Under the Curve)

#### ROC AUC

![ROC AUC 示意图]({{< static_ref "fig/ai/machine_learning/roc_auc.svg" >}}){#fig:roc_auc width=80%}

ROC AUC 表示随机正类别（绿色）样本位于随机负类别（红色）样本右侧的概率。[@ml_roc_auc]

#### PR AUC

PR AUC 表示在不同召回率阈值下的平均精确率。[@ml_pr_auc]

# 信息论

## 条件熵

$$
\begin{align}
H(Y\mid X) &= \sum_{x\in\mathcal{X}}p(x)H(Y\mid X=x) \\
&= -\sum_{x\in\mathcal{X},y\in\mathcal{Y}}p(x,y)\log\frac{p(x,y)}{p(x)}
\end{align}
$$ {#eq:conditional_entropy}

# 输出层

## sigmoid

$$f(z) = \frac{1}{1+e^{-z}}$$ {#eq:sigmoid}

# 损失函数

## 交叉熵

$$H(p, q) = -E_p[\log q]$$ {#eq:cross_entropy}

在离散情况下为

$$H(p, q) = -\sum_{x\in\mathcal{X}}p(x)\log q(x)$$ {#eq:cross_entropy_discrete}

# 参考文献
