---
title: "推荐系统"
---

# 术语

| 缩写 | 全称                              | 含义             |
|------|-----------------------------------|------------------|
| C    | Context                           | 场景             |
| CTR  | Click Through Rate                | 点击率           |
| CVR  | Conversion Rate                   | 转化率           |
| DMP  | Data Management Platform          | 数据管理平台     |
| FFM  | Field-aware Factorization Machine | 域感知因子分解机 |
| FM   | Factorization Machine             | 因子分解机       |
| I    | Item                              | 物品             |
| MLP  | Multilayer Perception             | 多层感知机       |
| U    | User                              | 用户             |

: 术语 {#tbl:terminology}

# 架构

![推荐系统架构]({{< static_ref "fig/AI/推荐系统/architecture.webp" >}}){#fig:architecture}

# 算法

## 不同算法的优缺点

| 算法          | 优点                                           | 缺点                     |
|---------------|------------------------------------------------|--------------------------|
| UserCF        | 符合直觉（兴趣相似的朋友喜欢的物品，我也喜欢） | 用户数远大于物品数       |
|               | 社交特性更强，适于发现热点                     | 用户历史数据向量很稀疏   |
| ItemCF        | 适于兴趣变化较为稳定的应用                     | 泛化能力弱，头部效应强   |
|               | 直观，可解释性强                               | 无法有效引入场景信息     |
| 矩阵分解      | 泛化能力强                                     | 不方便融合特征           |
|               | 空间复杂度低                                   | 不好冷启动               |
|               | 便于与神经网络集成                             |                          |
| 逻辑回归      | 融合多种特征                                   | 无法特征交叉、筛选       |
|               | 假设 $y$ 服从伯努利分布，有物理意义            |                          |
|               | 是各特征的加权和，可解释性强                   |                          |
|               | 易于并行化、模型简单、易于训练                 |                          |
| POLY2         | 特征交叉                                       | 特征向量更稀疏，不好训练 |
|               |                                                | 参数增多                 |
| FM            | 参数从 POLY2 的 $n^2$ 下降到 $nk$              |                          |
|               | 比 POLY2 更适于稀疏数据，泛化能力强            |                          |
|               | 易于上线                                       |                          |
| FFM           | 比 FM 表达能力强                               | 计算复杂度上升到 $kn^2$  |
| GBDT+LR       | 特征工程模型化                                 |                          |
| LS-PLM        | 能挖掘非线性模式                               |                          |
|               | 引入 L1 惩罚，模型稀疏                         |                          |
| AutoRec       | 第一次使用深度学习框架                         |                          |
| Deep Crossing | 特征间深度交叉                                 |                          |
| NeuralCF      | 用户向量和物品向量更充分地交叉                 | 没有引入更多特征         |
|               | 表达能力比矩阵分解强                           |                          |
|               | 可以灵活选择互操作层                           |                          |
| PNN           | 强调不同特征之间的交互                         | 简化操作丢失信息         |
| Wide & Deep   | 综合记忆能力和泛化能力                         |                          |
|               | 开拓了融合不同网络结构的新思路                 |                          |
| Deep & Cross  | Wide 部分的特征自动交叉                        |                          |
| DIEN          | 预测下一次购买，更符合业务目标                 | 训练复杂度高             |
|               |                                                | 串行推断                 |
| DRN           | 变静态为动态，在线训练                         |                          |

: 不同算法的优缺点 {#tbl:algorithm_pros_cons}

## 协同过滤

### 共现矩阵

用户为行坐标（记用户总数为 $m$）、物品为列坐标（即物品总数为 $n$）的 $m\times n$
维矩阵。

### 相似度

#### 余弦相似度

$$\sim(\v{i},\v{j}) = \cos(\v{i}, \v{j}) = \frac{\v{i}\cdot\v{j}}{\lVert\v{i}\rVert\cdot\lVert\v{j}\rVert}$$ {#eq:cosine_similarity}

其中，$\v{i}$、$\v{j}$ 均表示用户向量。

#### 皮尔逊相关系数

$$\sim(i,j) = \frac{\sum_{p\in P}(R_{i,p} - \mean{R_i})(R_{j,p}-\mean{R_j})}{\sqrt{\sum_{p\in P}(R_{i,p}-\mean{R_i})^2}\sqrt{\sum_{p\in P}(R_{j,p}-\mean{R_j})^2}}$$
{#eq:pearsion_coefficient}

其中，$R_{i,p}$ 表示用户 $i$ 对物品 $p$ 的评分；$\mean{R_i}$ 表示用户 $i$ 对所有
物品的平均评分；$P$ 代表所有物品的集合。

> 皮尔逊相关系数减小了用户评分偏置的影响。

#### 皮尔逊相关系数拓展

$$\sim(i,j) = \frac{\sum_{p\in P}(R_{i,p} - \mean{R_p})(R_{j,p}-\mean{R_p})}{\sqrt{\sum_{p\in P}(R_{i,p}-\mean{R_p})^2}\sqrt{\sum_{p\in P}(R_{j,p}-\mean{R_p})^2}}$$
{#eq:pearsion_coefficient_item}

其中，$R_{i,p}$ 表示用户 $i$ 对物品 $p$ 的评分；$\mean{R_p}$ 表示物品 $p$
的平均评分；$P$ 代表所有物品的集合。

> [@eq:pearsion_coefficient_item] 减小了物品评分偏置的影响。

### UserCF

基于用户的协同过滤。

$$R_{u,p} = \frac{\sum_{s\in S}w_{u,s}R_{s,p}}{\sum_{s\in S}w_{u,s}}$$
{#eq:user_cf}

其中，$R_{s,p}$ 表示用户 $s$ 对物品 $p$ 的评分；$w_{u,s}$ 表示用户 $u$
与用户 $s$ 的相似度。

- 根据用户向量找到 top n 相似用户
- 将相似用户对物品的评分加权平均，即可得到目标用户对物品的评分

### ItemCF

基于物品相似度的协同过滤。

$$R_{u,p} = \sum_{h\in H}w_{p,h}R_{u,h}$$
{#eq:item_cf}

其中，$R_{u,h}$ 表示用户 $u$ 对物品 $h$ 的评分；$w_{p,h}$ 表示物品 $p$
与物品 $h$ 的相似度；$H$ 表示用户 $u$ 的正反馈物品集合。

- 根据物品向量找到 top k 相似物品
- 将用户对相似物品的评分加权平均，即得用户对目标物品的评分

## 矩阵分解

分解共现矩阵得到用户和物品的隐向量：

$$\m{R} = \m{U}\m{V}$$ {#eq:matrix_factorization}

其中，$\m{R}$ 为 $m\times n$ 维的共现矩阵，$\m{U}$ 为 $m\times k$ 维的用户矩阵，
$\m{V}$ 为 $k\times n$ 维的物品矩阵。

$$\hat{r}_{ui} = \T{\v{q}}_i\v{p}_u$$ {#eq:matrix_factorization_r}

其中，$\v{p}_u$ 表示 $\m{U}$ 的第 $u$ 行组成的向量，$\v{q}_i$ 表示 $\m{V}$ 中的
第 $i$ 列组成的向量。

### 奇异值分解

- 共现矩阵有大量缺失值，不适于直接 SVD
- 计算复杂度高

### 梯度下降

损失函数：

$$\min\sum_{(u,i)\in K}(r_{ui} - \T{\v{q}}_i\v{p}_u)^2$$
{#eq:matrix_factorization_loss}

其中，$K$ 是所有用户评分样本的集合。

### 消除用户和物品打分的偏差

$$\hat{r}_{ui} = \mu + b_i + b_u + \T{\v{q}}_i\v{p}_u$$ {#eq:matrix_factorization_r_bias}

其中，$\mu$ 是全局偏差，$b_i$ 是物品偏差，$b_u$ 是用户偏差。

## 逻辑回归

### 输出

$$\hat{y} = \sigmoid(\T{\v{x}}\v{w} + b)$$ {#eq:lr_output}

### 损失函数

$$
\begin{align}
J(\v{w}) &= \frac{1}{m}\sum_{i=1}^m H(p(\v{y}), p(\hat{\v{y}})) \\
&= -\frac{1}{m}\sum_{i=1}^m[y_i\log f_{\v{w}}(\v{x}_i) + (1-y_i)\log (1-f_{\v{w}}(\v{x}_i))]
\end{align}
$$ {#eq:lr_loss}

> 也可以用极大似然估计解释，$P(y\mid \v{x};\v{w}) = (f_{\v{w}}(\v{x}))^y(1-f_{\v{w}}(\v{x}))^{1-y}$。

## FM -> FFM

### POLY2

$$\phi\mathrm{POLY2}(\v{w},\v{x}) =
\sum_{j_1=1}^{n-1}\sum_{j_2=j_1+1}^n w_{h(j_1,j_2)}x_{j_1}x_{j_2}$$
{#eq:poly2}

### FM

$$\phi\mathrm{FM}(\v{w},\v{x}) =
\sum_{j_1=1}^{n-1}\sum_{j_2=j_1+1}^n (\v{w}_{j_1}\cdot\v{w}_{j_2})x_{j_1}x_{j_2}$$
{#eq:fm}

### FFM

$$\phi\mathrm{FFM}(\v{w},\v{x}) =
\sum_{j_1=1}^{n-1}\sum_{j_2=j_1+1}^n (\v{w}_{j_1,f_2}\cdot\v{w}_{j_2,f_1})x_{j_1}x_{j_2}$$
{#eq:ffm}

## GBDT + LR

![GBDT+LR 架构]({{< static_ref "fig/AI/推荐系统/GBDT+LR_architecture.jpg" >}}){#fig:GBDT_LR_architecture}

## LS-PLM

### 输出

$$
\begin{align}
f(\v{x}) &= \sum_{i=1}^m \pi_i(\v{x})\cdot\eta_i(\v{x}) \\
&= \sum_{i=1}^m \frac{\e^{\v{\mu_i}\cdot\v{x}}}{\sum_{j=1}^m\e^{\v{\mu_j}\cdot\v{x}}}\cdot\frac{1}{1+\e^{-\v{w_i}\cdot\v{x}}}
\end{align}
$$ {#eq:ls_plm_y}

其中，$m$ 为分片数，$\pi$ 为聚类函数（这里采用 softmax 对样本进行多分类）。

## AutoRec

![AutoRec 架构[@sedhain2015autorec]]({{< static_ref "fig/AI/推荐系统/auto_rec_architecture.png" >}}){#fig:auto_rec_architecture}

### 损失函数

$$\min_{\theta}\left[\sum_{\v{r}\in S}\lVert\v{r}-h(\v{r};\theta)\rVert_2^2
+ \frac{\lambda}{2}(\lVert\m{W}_F^2\rVert + \lVert\m{V}\rVert_F^2)\right]$$
{#eq:auto_rec_loss}

其中，$h(\v{r};\theta)$ 为重建函数；$\v{r}^{(i)}=\T{(R_{1i},\dots,R_{mi})}$ 为物
品 $i$ 的评分向量。

### 重建函数

$$h(\v{r};\theta)=f(\m{W}\cdot g(\m{V}\v{r}+\mu)+b)$$ {#eq:auto_rec_reconstruction}

### 输出

$$\hat{R}_{ui} = h(\v{r}^{(i)};\theta)_u$$ {#eq:auto_rec_output}

## Deep Crossing

![Deep Crossing 架构[@shan2016deep]]({{< static_ref "fig/AI/推荐系统/deep_crossing_architecture.png" >}}){#fig:deep_crossing_architecture}

### 残差神经网络

好处：

- 减少过拟合
- 减弱梯度消失现象，加快收敛速度

## NeuralCF

用多层神经网络代替矩阵分解的内积操作。

![NeuralCF 架构[@he2017neural]]({{< static_ref "fig/AI/推荐系统/neural_cf_architecture.png" >}}){#fig:neural_cf_architecture}

## PNN

乘积层代替 Deep Crossing 模型中的 Stacking 层。

![PNN 架构[@qu2016product]]({{< static_ref "fig/AI/推荐系统/pnn_architecture.png" >}}){#fig:pnn_architecture}

## Wide & Deep

![Wide & Deep 架构[@cheng2016wide]]({{< static_ref "fig/AI/推荐系统/wide_deep_architecture.png" >}}){#fig:wide_deep_architecture}

Cross Product Transformation 为：

$$\phi_k(\v{x}) = \prod_{i=1}^d x_i^{c_{ki}}\quad c_{ki}\in\{0,1\}$$

其中，$c_{ki}$ 当第 $i$ 个特征属于第 $k$ 个组合特征时为 $1$，否则为 $0$；$x_i$
是第 $i$ 个特征的值。

## Deep & Cross

![Deep & Cross 架构[@wang2017deep]]({{< static_ref
"fig/AI/推荐系统/deep_cross_architecture.png"
>}}){#fig:deep_cross_architecture width=60%}

Cross 网络的运算为：

$$\v{x}_{l+1} = \v{x}_0\T{\v{x}_l}\v{w}_l + \v{b}_l + \v{x}_l$$ {#eq:deep_cross_cross}

## FNN

用 FM 的隐向量初始化 Embedding 层。

为什么 Embedding 层收敛速度较慢？

- Embedding 参数多
- 输入向量稀疏

![FNN 架构[@zhang2016deep]]({{< static_ref
"fig/AI/推荐系统/fnn_architecture.png"
>}}){#fig:fnn_architecture}

其中，$\v{w}$ 和 $\v{v}$ 对应于 FM 中的参数：

$$\hat{\v{y}} = \sigmoid\left(w_0 + \sum_{i=1}^N w_i x_i +
\sum_{i=1}^N\sum_{j=i+1}^N\langle\v{v}_i,\v{v}_j\rangle x_i x_j\right)
$$ {#eq:fm_output}

## DeepFM

![DeepFM 架构[@guo2017deepfm]]({{< static_ref
"fig/AI/推荐系统/deep_fm_architecture.png"
>}}){#fig:deep_fm_architecture}

## NFM

用神经网络代替 FM 的二阶特征交叉。

![NFM 架构[@he2017nfm]]({{< static_ref
"fig/AI/推荐系统/nfm_architecture.png"
>}}){#fig:nfm_architecture}

Bi-Interaction Pooling 具体操作为：

$$f_{\mathrm{BI}}(\mathcal{V}_x) = \sum_{i=1}^n\sum_{j=i+1}^n x_i\v{v}_i\odot
x_j\v{v}_j$$ {#eq:nfm_bi}

其中，$\mathcal{V}_x$ 是 Embedding 集合。

## AFM

![AFM 架构[@xiao2017attentional]]({{< static_ref
"fig/AI/推荐系统/afm_architecture.png"
>}}){#fig:afm_architecture}

特征交叉采用元素积：

$$f_{\mathrm{PI}}(\mathcal{E}) = \{(\v{v}_i\odot\v{v}_j) x_i x_j\mid
(i,j)\in\mathcal{R}_x\}$$ {#eq:afm_pi}

其中，PI 表示 Pair-wise Interaction Layer；$\mathcal{E} = \{\v{v}_i x_i\mid
i\in\mathcal{X}\}$；$\mathcal{X}$ 为非零特征的索引集合；$\mathcal{R}_x =
\{(i,j)\mid i\in\mathcal{X}, j\in\mathcal{X}, j>i\}$。

$$
\begin{align}
f_{\mathrm{Att}}(f_{\mathrm{PI}}(\mathcal{E})) &= \sum_{(i,j)\in\mathcal{R}_x}
a_{ij}(\v{v}_i\odot\v{v}_j) x_i x_j \\
a_{ij} &= \frac{\exp(a'_{ij})}{\sum_{(i,j)\in\mathcal{R}_x}\exp(a'_{ij})} \\
a'_{ij} &= \T{\v{h}}\ReLU(\m{W}(\v{v}_i\odot\v{v}_j)x_i x_j +\v{b})
\end{align}
$$ {#eq:afm_att}

## DIN

![DIN 架构[@zhou2018deep]]({{< static_ref
"fig/AI/推荐系统/din_architecture.png"
>}}){#fig:din_architecture}

### 注意力

$$\v{v}_U(A) = f(\v{v}_A,\v{e}_1,\v{e}_2,\dots,\v{e}_H)
= \sum_{j=1}^H a(\v{e}_j,\v{v}_A)\v{e}_j
= \sum_{j=1}^H w_j\v{e}_j$$ {#eq:din_attention}

其中，$\{\v{e}_1,\v{e}_2,\dots,\v{e}_H\}$ 是用户 U 的历史行为的 Embedding 向量；
$\v{v}_A$ 是广告 A 的 Embedding 向量。

## DIEN

![DIEN 架构[@zhou2019deep]]({{< static_ref
"fig/AI/推荐系统/dien_architecture.png"
>}}){#fig:dien_architecture}

### AUGRU

AUGRU 改变了更新门：

$$\tilde{\v{u}}'_t = a_t\v{u}'_t$$ {#eq:dien_update_gate}

## DRN

![深度强化学习推荐系统[@zheng2018drn]]({{< static_ref
"fig/AI/推荐系统/drn_deep_reinforcement_recommendation_system.png"
>}}){#fig:drn_deep_reinforcement_recommendation_system}

- State representation 为用户特征，Action representation 为候选新闻特征
- 用户向 Agent 请求新闻列表，Agent 根据 State representation 和 Action
  representation 选择最好的 Action 返回给用户，并获取用户反馈
- Action 和反馈日志会存入 Agent 的内存，Agent 每小时会利用内存中的日志更新推荐算
  法

![DRN Q 网络[@zheng2018drn]]({{< static_ref
"fig/AI/推荐系统/drn_q.png"
>}}){#fig:drn_q width=60%}

![DRN 模型框架[@zheng2018drn]]({{< static_ref
"fig/AI/推荐系统/drn_model_framework.png"
>}}){#fig:drn_model_framework}

### 竞争梯度下降法

![竞争梯度下降法[@zheng2018drn]]({{< static_ref
"fig/AI/推荐系统/drn_dueling_bandit_gradient_descent.png"
>}}){#fig:drn_dueling_bandit_gradient_descent width=60%}

$$\Delta\m{W} = \alpha\cdot\rand(-1,1)\cdot\m{W}$$ {#eq:drn_delta_w}

其中，$\alpha$ 是探索因子。

# Embedding

## 不同 Embedding 的优缺点

| Embedding | 优点         | 缺点           |
|-----------|--------------|----------------|
| Word2vec  | 奠基         |                |
| Item2vec  | 没有时间窗口 | 只有序列型结构 |
| EGES      | 缓解冷启动   |                |

: 不同 Embedding 的优缺点 {#tbl:embedding_pros_cons}

## Word2vec

![CBOW 与 Skip-gram 架构[@mikolov2013efficient]]({{< static_ref
"fig/AI/推荐系统/word2vec_architecture.png"
>}}){#fig:word2vec_architecture width=80%}

- 根据经验，Skip-gram 的效果更好

### 基本结构

![word2vec 基本网络结构[@rong2014word2vec]]({{< static_ref
"fig/AI/推荐系统/word2vec_base_net.png"
>}}){#fig:word2vec_base_net width=60%}

#### 输出

$$y_j = p(w_j\mid w_I)
= \frac{\exp(\T{\v{v}'_{w_j}}\v{v}_{w_I})}{\sum_{j'=1}^V\exp(\T{\v{v}'_{w_{j'}}}\v{v}_{w_I})}
$$ {#eq:word2vec_base_output}

其中，$\v{v}_{w_I}\in\R^{N\times 1}$ 为 $\m{W}$ 的第 $I$ 行；
$\v{v}'_{w_j}\in\R^{N\times 1}$ 为 $\m{W}'$ 的第 $j$ 列。$\m{W}$ 为词向量矩阵。

#### 损失函数

$$L = -\log p(w_O\mid w_I)$$ {#eq:word2vec_base_loss}

其中，$O$ 为输出单词的索引；这个损失可以看做最大似然概率，也可以看做交叉熵。

#### 负采样

$$L = -\log \sigma(\T{\v{v}'_{w_O}}\v{h})
- \sum_{w_j\in\mathcal{W}_{\mathrm{neg}}}\log\sigma(-\T{\v{v}'_{w_j}}\v{h})
$$ {#eq:word2vec_negative_sample}

其中，$w_O$ 是输出单词；$\mathcal{W}_{\mathrm{neg}} = \{w_j\mid j=1,\cdots,K\}$
是采样得到的负样本集合。

## Item2vec

## DeepWalk

![DeepWalk 架构[@wang2018billion]]({{< static_ref
"fig/AI/推荐系统/deep_walk_architecture.png"
>}}){#fig:deep_walk_architecture}

### 随机游走的转移概率[@wang2018billion]

$$
P(v_j\mid v_i) =
\begin{cases}
\frac{M_{ij}}{\sum_{j'\in N_+(v_i)}M_{ij'}}, &\mathrm{if}\;v_j\in N_+(v_i)\\
0, &\mathrm{if}\;e_{ij}\notin\mathcal{E}
\end{cases}
$$

其中，$N_+(v_i)$ 表示 $v_i$ 的出边集合；$M_{ij}$ 表示节点 $i$ 到节点 $j$ 边的权
重；$\mathcal{E}$ 表示所有边的集合。

## node2vec

![node2vec 广度优先搜索与深度优先搜索[@grover2016node2vec]]({{< static_ref
"fig/AI/推荐系统/node2vec_bfs_dfs.png"
>}}){#fig:node2vec_bfs_dfs width=60%}

- 同质性：[@fig:node2vec_bfs_dfs] 中的 $u$ 与 $s_1$ 属于同一社区，Embedding 应该
  相似
- 同构性：[@fig:node2vec_bfs_dfs] 中的 $u$ 与 $s_6$ 扮演相似的结构角色，
  Embedding 应该相似
- BFS 能发现同构性；DFS 能发现同质性

### 跳转概率

![node2vec 跳转概率[@grover2016node2vec]]({{< static_ref
"fig/AI/推荐系统/node2vec_transition.png"
>}}){#fig:node2vec_transition width=60%}

未归一化的跳转概率为：

$$\pi_{vx} = \alpha_{pq}(t,x)\cdot w_{vx}$$ {#eq:node2vec_transition}

其中，

$$
\alpha_{pq}(t,x) =
\begin{cases}
\frac{1}{p}\quad &\mathrm{if}\;d_{tx} = 0\\
1 &\mathrm{if}\;d_{tx} = 1\\
\frac{1}{q}\quad &\mathrm{if}\;d_{tx} = 2
\end{cases}
$$ {#eq:node2vec_alpha}

$t$ 为上一个节点；$w_{vx}$ 是边 $vx$ 的权重；$d_{tx}$ 表示节点 $t$ 与节点 $x$ 的
最短距离；$p$ 为返回参数；$q$ 为进出参数。

## EGES

![EGES 架构[@wang2018billion]]({{< static_ref
"fig/AI/推荐系统/eges_architecture.png"
>}}){#fig:eges_architecture width=60%}

### 隐层向量

$$\m{H}_v = \frac{\sum_{j=0}^n \e^{a_v^j}\m{W}_v^j}{\sum_{j=0}^n \e^{a_v^j}}$$

使用 $e^{a_v^j}$ 作为权重是想让权重总是大于 $0$。

## 局部敏感哈希

欧式空间中，将高维空间的点映射到低维空间：

- 原本相近的点在低维空间肯定依然相近
- 原本远离的点则有一定概率变成相近的点

$$h^{\v{x},b} = \left\lfloor\frac{\v{v}\cdot\v{x} + b}{w}\right\rfloor$$ {#eq:lsh_hash}

# 特征工程

## 原则

- 尽可能暴露有用信息
- 尽量摈弃冗余信息

# 召回策略

| 层     | 目标                             | 特点                                   |
|--------|----------------------------------|----------------------------------------|
| 召回层 | 尽量让用户感兴趣的物品被快速召回 | 候选集合大、速度快、模型简单、特征较少 |
| 排序层 | 得到精准的排序结果               | 候选集合小、模型复杂、特征较多         |

: 召回层与排序层 {#tbl:recall_sort}

# 冷启动的解决办法

## 基于规则的冷启动

## 丰富冷启动过程中可获得的用户和物品特征

- 用户的注册信息
- 第三方 DMP 提供的用户信息
- 物品的内容特征
- 引导用户输入的冷启动特征

## 利用主动学习、迁移学习和“探索与利用”机制

### “探索与利用”机制

UCB (Upper Confidence Bound，置信区间上界)：

$$\mathrm{UCB}(j) = \mean{x_j}+\sqrt{\frac{2\ln n}{n_j}}$$ {#eq:ucb}

其中，$\mean{x_j}$ 为第 $j$ 个物品的平均回报；$n_j$ 为第 $j$ 个物品的曝光次数；
$n$ 为所有物品的曝光次数。可以看到，UCB 倾向于推荐冷启动的物品。

# 推荐模型离线训练

## Spark MLib

## Parameter Server

- 分布式梯度下降策略：同步阻断 -> 异步非阻断
- 多 server
- 使用一致性哈希、参数范围拉取、参数范围推送，减小带宽

# 推荐系统的评估

## Holdout 检验

## K-fold 交叉验证

把 K 次评估指标的平均值作为最终的评估指标。

# 参考文献
