---
title: "机器学习"
---

# 采样[@wiki_sampling]

| 放回？ | 英文                | 含义                   |
|--------|---------------------|------------------------|
| 不放回 | without replacement | 每个样本最多被采样一次 |
| 放回   | with replacement    | 一个样本可能被采样多次 |

: 是否放回的区别 {#tbl:sample_replacement}

# 中位数

# 评估指标

|               | 实际 Positive                         | 实际 Negative                        |
|---------------|---------------------------------------|--------------------------------------|
| 预测 Positive | True Positive                         | False Positive（误报，Type I Error） |
| 预测 Negative | False Negative（漏报，Type II Error） | True Negative                        |

: 混淆矩阵 {#tbl:confusion_matrix}

## 精确率（Precision）

你认为的正样本，有多少猜对了（猜的精确性如何）[@ml_precision_recall]：

$$ P = \frac{\TP}{\TP + \FP}$$ {#eq:precision}

在信息检索领域这样定义[@ml_evaluation_measures]：

$$ P = \frac{\vert\{\textrm{relevant documents}\}\cap\{\textrm{retrieved documents}\}\vert}{\vert\{\textrm{retrieved documents}\}\vert}$$ {#eq:precision_information_retrieval}

### P@n

只考虑 top n 个查询结果。[@ml_evaluation_measures]

## 召回率（Recall）

正样本有多少被找出来了（召回了多少）[@ml_precision_recall]：

$$R = \frac{\TP}{\TP + \FN}$$ {#eq:recall}

## 准确率（Accuracy）

预测正确的结果占总样本的比例[@ml_accuracy]：

$$A = \frac{\TP+\TN}{\TP+\TN+\FP+\FN}$$ {#eq:accuracy}

## $F_1$

Precision 与 Recall 的调和均值：

$$\frac{2}{F_1} = \frac{1}{P} + \frac{1}{R}$$ {#eq:f1}

## 真阳性率（TPR）[@ml_tpr_fpr]

在所有实际为阳性的样本中，被正确地判断为阳性之比率：

$$ \TPR = \frac{\TP}{\TP + \FN}$$ {#eq:tpr}

与召回率定义相同。

## 伪阳性率（FPR）[@ml_tpr_fpr]

在所有实际为阴性的样本中，被错误地判断为阳性之比率：

$$ \FPR = \frac{\FP}{\FP + \TN}$$ {#eq:fpr}

## ROC 与 Precision-Recall 曲线[@ml_roc]

![一个 ROC 与 Precision-Recall 曲线例子]({{< static_ref "fig/AI/机器学习/roc_pr.png" >}}){#fig:roc_pr width=80%}

![ROC 与 Precision-Recall 曲线随阈值的动态变化]({{< static_ref "fig/AI/机器学习/roc_pr.gif" >}}){#fig:roc_pr_dynamic width=80%}

### ROC 与 P-R 曲线的比较[@ml_roc]

![样本不平衡时，ROC 与 Precision-Recall 曲线的比较]({{< static_ref "fig/AI/机器学习/roc_pr_imbalance.png" >}}){#fig:roc_pr_imbalance width=80%}

- 当正负样本不平衡时，P-R 曲线对误报更敏感

### AUC(Area Under the Curve)

#### ROC AUC

![ROC AUC 示意图]({{< static_ref "fig/AI/机器学习/roc_auc.svg" >}}){#fig:roc_auc width=80%}

ROC AUC 表示随机正类别（绿色）样本位于随机负类别（红色）样本右侧的概率。[@ml_roc_auc]

#### PR AUC

PR AUC 表示在不同召回率阈值下的平均精确率。[@ml_pr_auc]

## AveP(Average Precision) [@ml_evaluation_measures]

AveP 为 PR AUC，具体地：

$$\AveP = \int_0^1 p(r)\d r$$ {#eq:AveP}
$$\AveP = \sum_{k=1}^n P(k)\Delta r(k)$$ {#eq:AveP_sum}
$$\AveP = \frac{\sum_{k=1}^n P(k)\times \rel(k)}{\vert\{\textrm{relevant documents}\}\vert}$$ {#eq:AveP_k}

其中，

- $k$ 表示在检索文档序列里的排名
- $n$ 表示检索文档的总数，$P(k)$ 表示 top k 的精确率
- $\Delta r(k)$ 表示从项 $k-1$ 到 $k$ 的召回率变化
- $\rel(k)$ 是指示函数，项 $k$ 是相关文档时为 $1$，项 $k$ 不是相关文档时为 $0$

## MAP(Mean Average Precision)

$$\MAP = \frac{\sum_{q=1}^Q \AveP(q)}{Q}$$ {#eq:map}

其中 $Q$ 表示查询总数。

# 信息论

## 条件熵[@conditional_entropy]

$$
\begin{align}
H(Y\mid X) &= \sum_{x\in\mathcal{X}}p(x)H(Y\mid X=x) \\
&= -\sum_{x\in\mathcal{X},y\in\mathcal{Y}}p(x,y)\log\frac{p(x,y)}{p(x)}
\end{align}
$$ {#eq:conditional_entropy}

# 输出层

## sigmoid

$$f(z) = \frac{1}{1+e^{-z}}$$ {#eq:sigmoid}

# 损失函数

## 交叉熵[@cross_entropy]

$$H(p, q) = -E_p[\log q]$$ {#eq:cross_entropy}

在离散情况下为

$$H(p, q) = -\sum_{x\in\mathcal{X}}p(x)\log q(x)$$ {#eq:cross_entropy_discrete}

# 传统机器学习算法

## 决策树

- 分类树：$y$ 离散
- 回归树：$y$ 连续

### ID3[@decision_tree]

父节点的熵：

$$H(D) = -\sum_{k=1}^K\frac{|C_k|}{|D|}\log\frac{|C_k|}{|D|}$$

知道某个属性 A 后的条件熵：

$$H(D\mid A) = \sum_{i=1}^n\frac{|D_i|}{|D|}H(D_i)$$

信息增益：

$$\mathrm{Gain}(D, A) = H(D) - H(D\mid A)$$

缺点：

- 信息增益偏向 $|A|$ 大的属性

### C4.5

信息增益比：

$$\mathrm{Gain_{\mathrm{ratio}}}(D, A) = \frac{\mathrm{Gain}(D,A)}{H_A(D)}$$

其中，$H_A(D) = -\sum_{i=1}^n\frac{|D_i|}{|D|}\log\frac{|D_i|}{|D|}$。

缺点：

- 多叉树
- 只能分类

### CART

#### 分类

基尼系数：

$$\mathrm{Gini}(D) = \sum_{k=1}^K\frac{|C_k|}{|D|}\left(1-\frac{|C_k|}{|D|}\right)$$
$$\mathrm{Gini}(D, A) = \frac{|D_1|}{|D|}\mathrm{Gini}(D_1) + \frac{|D_2|}{|D|}\mathrm{Gini}(D_2)$$

用 $\mathrm{Gini}(D, A)$ 最小的属性 A 及切分点 a 分割 D。

#### 回归

按照

$$\min_{a, s}\left[\min_{c_1}\sum_{x_i\in D_1}(y_i - c_1)^2 + \min_{c_2}\sum_{x_i\in D_2}(y_i - c_2)^2\right]$$

选择属性 $a$ 与切分点 $s$。

## 随机森林

对 $b=1,\dots,B$：

- 从 $X,Y$ 进行 $n$ 次有放回的抽样，记为 $X_b,Y_b$
- 对 $X_b,Y_b$ 训练决策树 $f_b$；每次分裂时只从特征的随机子集里选择
- $\hat{f} = \frac{1}{B}\sum_{b=1}^B f_b(x)$

优点：

- 泛化能力强
- 能处理高维数据，可以降维
- 可以处理缺失数据
- 可以并行

缺点：

- 黑盒
- 噪声较大时容易过拟合

## GBDT

全称为 Gradient Boosting Decision Tree。

优点：

- 在分布稠密的数据集上，泛化能力和表达能力都很好
- 具有较好的解释性和鲁棒性，能够自动发现特征间的高阶关系

缺点：

- 在高维稀疏的数据集上，表现不如支持向量机或者神经网络
- 需要迭代训练，即串行计算

### 损失函数

Square loss:

$$L(y, F) = \frac{1}{2}(y-F(x))^2$$

Absolute loss:

$$L(y, F) = |y-F(x)|$$

Huber loss:

$$
L(y, F) =
\begin{cases}
\frac{1}{2}(y-F(x))^2, & |y-F(x)| \le\delta\\
\delta(|y-F(x)| - \frac{\delta}{2}), & |y-F(x)| > \delta
\end{cases}
$$

| 损失函数      | 优点         | 缺点       |
|---------------|--------------|------------|
| Square loss   | 数学性质好   | 对噪声敏感 |
| Absolute loss | 对噪声鲁棒   |            |
| Huber loss    | 对噪声更鲁棒 |            |

: 不同损失函数的比较 {#tbl:gbdt_loss_compare}

### 回归的学习步骤

1. 初始化 $F(x) = \frac{\sum_{i=1}^n y_i}{n}$
2. 计算负梯度：$-g(x_i) = -\frac{\partial L(y_i,F(x_i))}{\partial F(x_i)}$
3. 按 $-g(x_i)$ 拟合回归树 $h$
4. 更新 F，$F := F + \rho h$
5. 终止或者跳到步骤 2

## XGBoost

### 树的输出

$$f^{(t)}(\v{x}) = w_{q(\v{x})}, \v{w}\in \R^T, q: \R^d\to \{1,2,\cdots,T\}$$

其中，$T$ 为叶子节点的数量；$d$ 为 $\v{x}$ 的维度；$q$ 把 $\v{x}$ 映射到某个叶子
序号。

$$w_j = -\frac{G_j}{H_j + \lambda}$$
$$G_j = \sum_{i\in I_j}g_i$$
$$H_j = \sum_{i\in I_j}h_i$$
$$I_j = \{i\mid q(\v{x}_i) = j\}$$
$$g_i = \frac{\partial l(y_i, \hat{y}_i^{(t-1)})}{\partial\hat{y}_i^{(t-1)}}$$
$$h_i = \frac{\partial^2 l(y_i, \hat{y}_i^{(t-1)})}{{\partial\hat{y}_i^{(t-1)}}^2}$$

### 树的损失函数

$$J(f^{(t)}) = -\frac{1}{2}\sum_{j=1}^T\frac{G_j^2}{H_j+\lambda} + \gamma T$$

### 节点分裂的增益

$$\mathrm{Gain} = \frac{1}{2}\left[\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}-\frac{(G_L+G_R)^2}{H_L+H_R+\lambda}\right] - \gamma$$

优点：

- 比 GBDT 性能更好
- 并行优化

与 GBDT 的区别：

- 除了支持 CART 树，还支持线性分类器
- 加了二阶导数
- 加了正则项，防止过拟合
- 支持列抽样
- 可以自动学习缺失值的分裂方向
- 预先排序，并行计算不同特征的增益

## LightGBM

与 XGBoost 的区别：

- XGBoost 是 pre-sorted 算法，寻找数据分割点更精确；LightGBM 是 histogram 算法，
  占用内存小，计算复杂度低
- XGBoost 是 level-wise 分裂，LightGBM 是 leaf-wise
- XGBoost 使用 pre-sorted 算法，通信代价大；LightGBM 使用 histogram 算法，通信代
  价小，能并行计算

## K means

### 背景

给定样本 $\{\v{x}_1, \v{x}_2, \dots, \v{x}_n\}$，K means 希望把样本分成 $k$ 类
$\set{S} = \{\set{S}_1, \set{S}_2, \dots, \set{S}_k\}$，并且满足[@eq:k_means_object]：

$$
\argmin_{\set{S}}\sum_{i=1}^k\sum_{\v{x}\in\set{S}_i}\lVert\v{x}-\v{\mu}_i\rVert^2
$$ {#eq:k_means_object}

### 迭代步骤

给定 k 个质心的初始值，然后重复以下步骤

- 赋值：把每个样本赋成距离最近的质心所在的类
- 更新：重新计算每个类的质心

### 初始化方法

- Forgy：随机选择 k 个样本作为质心
- Random Partition：每个样本随机赋一个类，计算每个类的质心

# 参考文献
